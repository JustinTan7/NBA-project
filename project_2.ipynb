{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Preparing and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data set length: 31550 rows\n",
      "Length of data set after dropping the 2024 season: 31135 rows\n",
      "Length of data set after dropping all rows with less than 10 games played: 27308 rows\n",
      "Columns with missing data:\n",
      "Age      12\n",
      "GS     7706\n",
      "MP      939\n",
      "3P     5725\n",
      "3PA    5725\n",
      "3P%    8346\n",
      "2P%       1\n",
      "FT%      85\n",
      "ORB    4153\n",
      "DRB    4153\n",
      "TRB     769\n",
      "STL    4969\n",
      "BLK    4968\n",
      "TOV    5068\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Columns with missing data after filling:\n",
      "3P%    0\n",
      "2P%    0\n",
      "FT%    0\n",
      "Age    0\n",
      "GS     0\n",
      "MP     0\n",
      "3P     0\n",
      "3PA    0\n",
      "ORB    0\n",
      "DRB    0\n",
      "TRB    0\n",
      "STL    0\n",
      "BLK    0\n",
      "TOV    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "nba_df = pd.read_csv('player_totals.csv', encoding = 'unicode_escape', engine ='python')\n",
    "\n",
    "print(f\"Original data set length: {len(nba_df)} rows\")\n",
    "\n",
    "season2024_condition = nba_df['Season'] > 2023\n",
    "nba_df.drop(index=nba_df[season2024_condition].index, inplace=True)\n",
    "\n",
    "# season2005_condition = nba_df['Season'] <= 2005\n",
    "# nba_df.drop(index=nba_df[season2005_condition].index, inplace=True)\n",
    "\n",
    "# targeting modern game\n",
    "\n",
    "print(f\"Length of data set after dropping the 2024 season: {len(nba_df)} rows\")\n",
    "\n",
    "gp_condition = nba_df[\"GP\"] <= 10\n",
    "nba_df.drop(index=nba_df[gp_condition].index, inplace=True)\n",
    "\n",
    "print(f\"Length of data set after dropping all rows with less than 10 games played: {len(nba_df)} rows\")\n",
    "\n",
    "# nba_df = nba_df.dropna()\n",
    "\n",
    "# print(f\"Length of data set after dropping all rows with NA values: {len(nba_df)} rows\")\n",
    "\n",
    "missing_data = nba_df.isnull().sum()\n",
    "\n",
    "print(\"Columns with missing data:\")\n",
    "print(missing_data[missing_data > 0])\n",
    "print(\"\\n\")\n",
    "\n",
    "columns_to_fill = ['3P%', '2P%', 'FT%', 'Age', 'GS', 'MP', '3P', '3PA', 'ORB', 'DRB', 'TRB', 'STL', 'BLK', 'TOV']\n",
    "\n",
    "nba_df[columns_to_fill] = nba_df[columns_to_fill].fillna(0)\n",
    "\n",
    "missing_data_updated = nba_df[columns_to_fill].isnull().sum()\n",
    "\n",
    "print('Columns with missing data after filling:')\n",
    "print(missing_data_updated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Linear Regression (Non-negative predictions):\n",
      "MSE: 40094.83616378065\n",
      "MAE: 131.12368250218483\n",
      "R-squared: 0.831182620575668\n",
      "Minimum y points from predicted: 0.0\n",
      "Max y points from predicted: 1793.8716607451993\n",
      "Minimum y points from tested: 2\n",
      "Max y points from test: 3033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Extract features and target variable\n",
    "X = nba_df[[\"GP\", \"MP\", \"FG%\",\"3P%\", \"2P%\", \"FT%\"]]\n",
    "# X = nba_df[[\"GP\", \"MP\", \"2P\", \"FG\", \"FGA\", \"3PA\", \"3P\", \"2PA\", \"FT\" ]]\n",
    "y_pts = nba_df[\"PTS\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_pts_train, y_pts_test = train_test_split(\n",
    "    X, y_pts, test_size=0.4, random_state=13\n",
    ")\n",
    "\n",
    "# Create and fit the scaler on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train linear regression model on scaled data\n",
    "model_pts_scaled = LinearRegression().fit(X_train_scaled, y_pts_train)\n",
    "\n",
    "# Predictions on scaled data\n",
    "y_pts_pred_scaled = model_pts_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Post-process the predictions to ensure non-negativity\n",
    "y_pts_pred_scaled_non_negative = np.maximum(y_pts_pred_scaled, 0)\n",
    "\n",
    "# Evaluation for Points (PTS) on scaled data\n",
    "mse_pts_scaled = mean_squared_error(y_pts_test, y_pts_pred_scaled_non_negative)\n",
    "mae_pts_scaled = mean_absolute_error(y_pts_test, y_pts_pred_scaled_non_negative)\n",
    "r2_pts_scaled = r2_score(y_pts_test, y_pts_pred_scaled_non_negative)\n",
    "min_y_pts_pred = min(y_pts_pred_scaled_non_negative)\n",
    "max_y_pts_pred = max(y_pts_pred_scaled_non_negative)\n",
    "min_y_pts_test = min(y_pts_test)\n",
    "max_y_pts_test = max(y_pts_test)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Linear Regression (Non-negative predictions):\")\n",
    "print(f\"MSE: {mse_pts_scaled}\")\n",
    "print(f\"MAE: {mae_pts_scaled}\")\n",
    "print(f\"R-squared: {r2_pts_scaled}\")\n",
    "print(f\"Minimum y points from predicted: {min_y_pts_pred}\")\n",
    "print(f\"Max y points from predicted: {max_y_pts_pred}\")\n",
    "print(f\"Minimum y points from tested: {min_y_pts_test}\")\n",
    "print(f\"Max y points from test: {max_y_pts_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Justification\n",
    "The choice to use linear regression was due to the fact that the relationship between the features and the target variable was linear. So any changes to one of them would affect the outcome of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Untuned Random Forest Model:\n",
      "MSE: 26552.490437486267\n",
      "MAE: 104.67685005492496\n",
      "R-squared: 0.886211854636577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_pts_train, y_pts_test = train_test_split(\n",
    "    X, y_pts, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# Create and fit the scaler on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Random Forest regression model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model to the scaled data\n",
    "rf_model.fit(X_train_scaled, y_pts_train)\n",
    "\n",
    "# Predictions on scaled data\n",
    "y_pts_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation for Points (PTS) with untuned Random Forest model and scaling\n",
    "mse_pts_rf = mean_squared_error(y_pts_test, y_pts_pred_rf)\n",
    "mae_pts_rf = mean_absolute_error(y_pts_test, y_pts_pred_rf)\n",
    "r2_pts_rf = r2_score(y_pts_test, y_pts_pred_rf)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Untuned Random Forest Model:\")\n",
    "print(f\"MSE: {mse_pts_rf}\")\n",
    "print(f\"MAE: {mae_pts_rf}\")\n",
    "print(f\"R-squared: {r2_pts_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Retraining with Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "1080 fits failed out of a total of 4320.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "288 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "792 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [            nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -21079.65886731\n",
      " -20835.85146112 -20789.49771404 -21085.67783004 -20934.98665907\n",
      " -20843.32986912 -20922.7479903  -20969.63728686 -20874.96953548\n",
      " -21175.68064156 -20912.97625819 -20788.23967995 -21314.77717717\n",
      " -20894.96096905 -20843.87752333 -21314.30253186 -21160.23948722\n",
      " -20987.40044086 -21378.65337377 -21186.84421285 -21046.65448807\n",
      " -21378.65337377 -21186.84421285 -21046.65448807 -21305.93157635\n",
      " -21168.3313448  -21040.38183073 -21079.65886731 -20835.85146112\n",
      " -20789.49771404 -21085.67783004 -20934.98665907 -20843.32986912\n",
      " -20922.7479903  -20969.63728686 -20874.96953548 -21175.68064156\n",
      " -20912.97625819 -20788.23967995 -21314.77717717 -20894.96096905\n",
      " -20843.87752333 -21314.30253186 -21160.23948722 -20987.40044086\n",
      " -21378.65337377 -21186.84421285 -21046.65448807 -21378.65337377\n",
      " -21186.84421285 -21046.65448807 -21305.93157635 -21168.3313448\n",
      " -21040.38183073 -21567.75278158 -21355.62133125 -21210.31116756\n",
      " -21465.89558227 -21318.25526381 -21168.43759725 -21304.96533893\n",
      " -21202.5944611  -21059.4974324  -21337.98326029 -21227.77780919\n",
      " -21123.80795671 -21299.6832444  -21163.10366249 -21107.56974895\n",
      " -21149.83245367 -21062.28162129 -20988.83473156 -21129.44837599\n",
      " -20992.58904985 -20931.03419353 -21129.44837599 -20992.58904985\n",
      " -20931.03419353 -21123.11358835 -20999.56297075 -20953.44239265\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -22008.93627042\n",
      " -21730.62649795 -21559.85464047 -21791.28193687 -21563.73682676\n",
      " -21483.44667816 -21729.7952028  -21612.2154841  -21477.01976851\n",
      " -21788.75367739 -21574.18978952 -21588.16847915 -21547.47849496\n",
      " -21532.80245673 -21460.55776115 -21538.2066276  -21630.68700447\n",
      " -21502.2663622  -21785.17225305 -21726.11453811 -21614.10186995\n",
      " -21785.17225305 -21726.11453811 -21614.10186995 -21792.35606052\n",
      " -21738.72987928 -21615.07976155 -22008.93627042 -21730.62649795\n",
      " -21559.85464047 -21791.28193687 -21563.73682676 -21483.44667816\n",
      " -21729.7952028  -21612.2154841  -21477.01976851 -21788.75367739\n",
      " -21574.18978952 -21588.16847915 -21547.47849496 -21532.80245673\n",
      " -21460.55776115 -21538.2066276  -21630.68700447 -21502.2663622\n",
      " -21785.17225305 -21726.11453811 -21614.10186995 -21785.17225305\n",
      " -21726.11453811 -21614.10186995 -21792.35606052 -21738.72987928\n",
      " -21615.07976155 -21182.83575778 -21000.81356229 -20925.54521372\n",
      " -21198.93620728 -21068.017133   -20966.62070609 -21140.2890248\n",
      " -21033.80127982 -20951.27917278 -21126.89330156 -20993.87692813\n",
      " -20935.25122471 -21100.28555166 -20982.65824316 -20921.63902986\n",
      " -21029.17422219 -20979.6708801  -20921.0891803  -21053.35656897\n",
      " -20965.69233013 -20895.27473117 -21053.35656897 -20965.69233013\n",
      " -20895.27473117 -21036.17191393 -20972.54757859 -20915.42158904\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -21305.04239352\n",
      " -20959.17314997 -20837.47663817 -21190.11053896 -21086.1827625\n",
      " -20823.90171981 -20908.23224208 -20938.55139351 -20871.06466273\n",
      " -20947.44151508 -20842.51119086 -20785.27944054 -21293.28617947\n",
      " -20954.09149793 -20860.71934571 -21230.94044992 -21116.2274703\n",
      " -20954.91484846 -21392.20294381 -21173.66139855 -21048.34511679\n",
      " -21392.20294381 -21173.66139855 -21048.34511679 -21307.09329194\n",
      " -21164.94159605 -21040.23340186 -21305.04239352 -20959.17314997\n",
      " -20837.47663817 -21190.11053896 -21086.1827625  -20823.90171981\n",
      " -20908.23224208 -20938.55139351 -20871.06466273 -20947.44151508\n",
      " -20842.51119086 -20785.27944054 -21293.28617947 -20954.09149793\n",
      " -20860.71934571 -21230.94044992 -21116.2274703  -20954.91484846\n",
      " -21392.20294381 -21173.66139855 -21048.34511679 -21392.20294381\n",
      " -21173.66139855 -21048.34511679 -21307.09329194 -21164.94159605\n",
      " -21040.23340186 -21658.61484635 -21389.96395671 -21237.77719967\n",
      " -21528.99424355 -21321.67119602 -21175.64571415 -21289.01526573\n",
      " -21188.60092143 -21057.69624463 -21336.23686954 -21211.36013547\n",
      " -21120.99457087 -21297.7633637  -21164.97007224 -21100.40698998\n",
      " -21146.657477   -21060.38806457 -20990.00786981 -21129.61839401\n",
      " -20992.13946791 -20931.02059081 -21129.61839401 -20992.13946791\n",
      " -20931.02059081 -21123.15514549 -20999.25432911 -20953.2859941\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -21098.04064492\n",
      " -20857.70117347 -20802.20785856 -21085.67783004 -20934.98665907\n",
      " -20843.32986912 -20922.7479903  -20969.63728686 -20874.96953548\n",
      " -21175.68064156 -20912.97625819 -20788.23967995 -21314.77717717\n",
      " -20894.96096905 -20843.87752333 -21314.30253186 -21160.23948722\n",
      " -20987.40044086 -21378.65337377 -21186.84421285 -21046.65448807\n",
      " -21378.65337377 -21186.84421285 -21046.65448807 -21305.93157635\n",
      " -21168.3313448  -21040.38183073 -21098.04064492 -20857.70117347\n",
      " -20802.20785856 -21085.67783004 -20934.98665907 -20843.32986912\n",
      " -20922.7479903  -20969.63728686 -20874.96953548 -21175.68064156\n",
      " -20912.97625819 -20788.23967995 -21314.77717717 -20894.96096905\n",
      " -20843.87752333 -21314.30253186 -21160.23948722 -20987.40044086\n",
      " -21378.65337377 -21186.84421285 -21046.65448807 -21378.65337377\n",
      " -21186.84421285 -21046.65448807 -21305.93157635 -21168.3313448\n",
      " -21040.38183073 -21569.0194783  -21356.44515481 -21210.82335553\n",
      " -21465.89558227 -21318.25526381 -21168.43759725 -21304.96533893\n",
      " -21202.5944611  -21059.4974324  -21337.98326029 -21227.77780919\n",
      " -21123.80795671 -21299.6832444  -21163.10366249 -21107.56974895\n",
      " -21149.83245367 -21062.28162129 -20988.83473156 -21129.44837599\n",
      " -20992.58904985 -20931.03419353 -21129.44837599 -20992.58904985\n",
      " -20931.03419353 -21123.11358835 -20999.56297075 -20953.44239265\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -21242.36456204\n",
      " -21254.47106177 -21117.24455859 -21200.75561108 -21187.95488827\n",
      " -21200.75176229 -21181.01923144 -21057.09906355 -21004.03464998\n",
      " -21191.92967764 -21002.04082024 -21028.6462935  -21267.99730478\n",
      " -21016.48843996 -20905.18340133 -21281.19080961 -21056.53114147\n",
      " -20973.84112309 -21089.62298832 -21031.76585842 -20984.96806127\n",
      " -21089.62298832 -21031.76585842 -20984.96806127 -21236.9219822\n",
      " -21111.09022196 -20968.02982261 -21242.36456204 -21254.47106177\n",
      " -21117.24455859 -21200.75561108 -21187.95488827 -21200.75176229\n",
      " -21181.01923144 -21057.09906355 -21004.03464998 -21191.92967764\n",
      " -21002.04082024 -21028.6462935  -21267.99730478 -21016.48843996\n",
      " -20905.18340133 -21281.19080961 -21056.53114147 -20973.84112309\n",
      " -21089.62298832 -21031.76585842 -20984.96806127 -21089.62298832\n",
      " -21031.76585842 -20984.96806127 -21236.9219822  -21111.09022196\n",
      " -20968.02982261 -37425.60338275 -37383.55549316 -37425.25760847\n",
      " -36475.50188698 -36463.59493733 -36449.49714137 -34545.43884766\n",
      " -34537.83007658 -34527.88061404 -38114.59864758 -38133.75916925\n",
      " -38141.1268264  -37520.56518441 -37521.81510831 -37532.43466751\n",
      " -34853.68690212 -34839.7282716  -34840.57639151 -32412.62105305\n",
      " -32412.14246857 -32410.17125114 -32412.62105305 -32412.14246857\n",
      " -32410.17125114 -31448.23987985 -31442.23007266 -31439.05574783\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -21681.98120638\n",
      " -21574.38241709 -21576.58543161 -21860.8494225  -21673.57734177\n",
      " -21645.86592903 -21578.37692734 -21531.21096827 -21548.3980648\n",
      " -21672.85994458 -21556.58008596 -21607.00511245 -22027.39109491\n",
      " -21720.81272291 -21566.68658614 -21514.32952183 -21502.74047414\n",
      " -21474.73748681 -21938.28311997 -21802.88243411 -21658.71966852\n",
      " -21938.28311997 -21802.88243411 -21658.71966852 -21746.00941246\n",
      " -21677.43825561 -21617.53152494 -21681.98120638 -21574.38241709\n",
      " -21576.58543161 -21860.8494225  -21673.57734177 -21645.86592903\n",
      " -21578.37692734 -21531.21096827 -21548.3980648  -21672.85994458\n",
      " -21556.58008596 -21607.00511245 -22027.39109491 -21720.81272291\n",
      " -21566.68658614 -21514.32952183 -21502.74047414 -21474.73748681\n",
      " -21938.28311997 -21802.88243411 -21658.71966852 -21938.28311997\n",
      " -21802.88243411 -21658.71966852 -21746.00941246 -21677.43825561\n",
      " -21617.53152494 -31610.77321157 -31559.40283745 -31551.30004911\n",
      " -31071.53528955 -31025.80469143 -31022.69224612 -30786.10863041\n",
      " -30790.4409159  -30776.17792656 -32220.35473897 -32229.27654921\n",
      " -32239.92790268 -32092.21031144 -32085.20588909 -32082.64417603\n",
      " -31351.49755416 -31350.39774298 -31349.97121771 -30298.95423417\n",
      " -30295.8767338  -30290.84830343 -30298.95423417 -30295.8767338\n",
      " -30290.84830343 -29549.62244193 -29550.47071944 -29549.42674734\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -21851.09861119\n",
      " -21475.48232481 -21246.46200204 -21118.37546929 -21131.86512411\n",
      " -21095.66664812 -21253.70702623 -21095.10478377 -21000.32024008\n",
      " -21189.68119166 -21125.44979097 -21034.88819558 -21263.12975216\n",
      " -21152.11707909 -21000.25515489 -21373.70023476 -21107.36817663\n",
      " -21052.46486045 -21060.20145588 -20977.12036249 -20950.72749119\n",
      " -21060.20145588 -20977.12036249 -20950.72749119 -21197.73148929\n",
      " -21107.55916666 -20946.58690116 -21851.09861119 -21475.48232481\n",
      " -21246.46200204 -21118.37546929 -21131.86512411 -21095.66664812\n",
      " -21253.70702623 -21095.10478377 -21000.32024008 -21189.68119166\n",
      " -21125.44979097 -21034.88819558 -21263.12975216 -21152.11707909\n",
      " -21000.25515489 -21373.70023476 -21107.36817663 -21052.46486045\n",
      " -21060.20145588 -20977.12036249 -20950.72749119 -21060.20145588\n",
      " -20977.12036249 -20950.72749119 -21197.73148929 -21107.55916666\n",
      " -20946.58690116 -37498.82056997 -37430.89955431 -37417.6000836\n",
      " -36435.74287767 -36468.33169776 -36443.12052662 -34550.96890551\n",
      " -34535.61930735 -34539.58118793 -38186.77192937 -38169.89736389\n",
      " -38143.1108876  -37490.46024099 -37528.24595091 -37535.37739691\n",
      " -34850.76927727 -34844.43045546 -34846.99014798 -32412.62105305\n",
      " -32412.14246857 -32410.17125114 -32412.62105305 -32412.14246857\n",
      " -32410.17125114 -31448.23987985 -31442.23007266 -31439.05574783\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -21255.32455807\n",
      " -21284.28538971 -21146.98564553 -21205.87185036 -21190.30204808\n",
      " -21201.86459905 -21181.01923144 -21057.09906355 -21004.03464998\n",
      " -21191.92967764 -21002.04082024 -21028.6462935  -21267.99730478\n",
      " -21016.48843996 -20905.18340133 -21281.19080961 -21056.53114147\n",
      " -20973.84112309 -21089.62298832 -21031.76585842 -20984.96806127\n",
      " -21089.62298832 -21031.76585842 -20984.96806127 -21236.9219822\n",
      " -21111.09022196 -20968.02982261 -21255.32455807 -21284.28538971\n",
      " -21146.98564553 -21205.87185036 -21190.30204808 -21201.86459905\n",
      " -21181.01923144 -21057.09906355 -21004.03464998 -21191.92967764\n",
      " -21002.04082024 -21028.6462935  -21267.99730478 -21016.48843996\n",
      " -20905.18340133 -21281.19080961 -21056.53114147 -20973.84112309\n",
      " -21089.62298832 -21031.76585842 -20984.96806127 -21089.62298832\n",
      " -21031.76585842 -20984.96806127 -21236.9219822  -21111.09022196\n",
      " -20968.02982261 -37425.60338275 -37383.55549316 -37425.25760847\n",
      " -36475.50188698 -36463.59493733 -36449.49714137 -34545.43884766\n",
      " -34537.83007658 -34527.88061404 -38114.59864758 -38133.75916925\n",
      " -38141.1268264  -37520.56518441 -37521.81510831 -37532.43466751\n",
      " -34853.68690212 -34839.7282716  -34840.57639151 -32412.62105305\n",
      " -32412.14246857 -32410.17125114 -32412.62105305 -32412.14246857\n",
      " -32410.17125114 -31448.23987985 -31442.23007266 -31439.05574783]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Grid Search Random Forest Regression Model:\n",
      "MSE: 19608.219048988718\n",
      "MAE: 89.50737766107683\n",
      "R-squared: 0.9002036252380352\n",
      "Grid Search took 793.99 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_pts_train, y_pts_test = train_test_split(\n",
    "    X, y_pts, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# Create and fit the scaler on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the hyperparameter grid for Random Forest\n",
    "# CHANGE THE PARAMETERS TO 6\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Create the Random Forest regression model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train_scaled, y_pts_train)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a new Random Forest model with the best hyperparameters\n",
    "best_rf_model = RandomForestRegressor(random_state=42, **best_params).fit(X_train_scaled, y_pts_train)\n",
    "\n",
    "# Predictions\n",
    "y_pts_pred_tuned_rf = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation for Points (PTS) with tuned Random Forest model\n",
    "mse_pts_tuned_rf = mean_squared_error(y_pts_test, y_pts_pred_tuned_rf)\n",
    "mae_pts_tuned_rf = mean_absolute_error(y_pts_test, y_pts_pred_tuned_rf)\n",
    "r2_pts_tuned_rf = r2_score(y_pts_test, y_pts_pred_tuned_rf)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Grid Search Random Forest Regression Model:\")\n",
    "print(f\"MSE: {mse_pts_tuned_rf}\")\n",
    "print(f\"MAE: {mae_pts_tuned_rf}\")\n",
    "print(f\"R-squared: {r2_pts_tuned_rf}\")\n",
    "print(f\"Grid Search took {elapsed_time_rounded} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Retraining with Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "15 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [-29549.62244193 -37383.55549316 -21785.17225305             nan\n",
      " -20934.98665907             nan             nan -31442.23007266\n",
      " -21246.46200204 -21040.23340186]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Randomized Search Random Forest Regression Model:\n",
      "MSE: 19752.866031005913\n",
      "MAE: 90.05895923429973\n",
      "R-squared: 0.8994674418860689\n",
      "Randomized Search took 11.45 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_pts_train, y_pts_test = train_test_split(\n",
    "    X, y_pts, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# Create and fit the scaler on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the hyperparameter grid for Random Forest\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Create the Random Forest regression model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "randomized_search = RandomizedSearchCV(rf_model, param_distributions=param_dist, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model to the data\n",
    "randomized_search.fit(X_train_scaled, y_pts_train)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = randomized_search.best_params_\n",
    "\n",
    "# Create a new Random Forest model with the best hyperparameters\n",
    "best_rf_model = RandomForestRegressor(random_state=42, **best_params).fit(X_train_scaled, y_pts_train)\n",
    "\n",
    "# Predictions\n",
    "y_pts_pred_tuned_rf = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation for Points (PTS) with tuned Random Forest model\n",
    "mse_pts_tuned_rf = mean_squared_error(y_pts_test, y_pts_pred_tuned_rf)\n",
    "mae_pts_tuned_rf = mean_absolute_error(y_pts_test, y_pts_pred_tuned_rf)\n",
    "r2_pts_tuned_rf = r2_score(y_pts_test, y_pts_pred_tuned_rf)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Randomized Search Random Forest Regression Model:\")\n",
    "print(f\"MSE: {mse_pts_tuned_rf}\")\n",
    "print(f\"MAE: {mae_pts_tuned_rf}\")\n",
    "print(f\"R-squared: {r2_pts_tuned_rf}\")\n",
    "\n",
    "print(f\"Randomized Search took {elapsed_time_rounded} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Untuned k-Nearest Neigbours Regression\n",
      "MSE: 31116.79576711827\n",
      "MAE: 115.98396191871107\n",
      "R-squared: 0.8666519628985883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X and y are your features and target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_pts, test_size=0.4, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create kNN regression model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors\n",
    "\n",
    "# Fit the model to the data\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Untuned k-Nearest Neigbours Regression\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Retraining with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression\n",
      "MSE: 22665.662973350594\n",
      "MAE: 99.85248456114738\n",
      "R-squared: 0.8846427107599278\n",
      "Grid Search took 8.9 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# Assuming X and y are your features and target variable\n",
    "X = nba_df[[\"GP\", \"MP\", \"FG%\", \"3P%\", \"2P%\", \"FT%\"]]\n",
    "y_pts = nba_df[\"PTS\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_pts, test_size=0.4, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "param_grid= {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': [20, 30, 40],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create kNN regression model\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(knn_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a new KNN model with the best hyperparameters\n",
    "best_knn_model = KNeighborsRegressor(**best_params).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pts_pred_tuned_knn = best_knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pts_pred_tuned_knn)\n",
    "mae = mean_absolute_error(y_test, y_pts_pred_tuned_knn)\n",
    "r2 = r2_score(y_test, y_pts_pred_tuned_knn)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Grid Search took {elapsed_time_rounded} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Retraining with Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression (Randomized Search)\n",
      "MSE: 22665.662973350594\n",
      "MAE: 99.85248456114738\n",
      "R-squared: 0.8846427107599278\n",
      "Randomized Search took 1.5 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Assuming X and y are your features and target variable\n",
    "X = nba_df[[\"GP\", \"MP\", \"FG%\", \"3P%\", \"2P%\", \"FT%\"]]\n",
    "y_pts = nba_df[\"PTS\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_pts, test_size=0.4, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "param_dist = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': [20, 30, 40],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create kNN regression model\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "random_search = RandomizedSearchCV(knn_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='neg_mean_squared_error', n_jobs=1, random_state=42)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model to the data\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Create a new KNN model with the best hyperparameters\n",
    "best_knn_model = KNeighborsRegressor(**best_params).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pts_pred_tuned_knn = best_knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pts_pred_tuned_knn)\n",
    "mae = mean_absolute_error(y_test, y_pts_pred_tuned_knn)\n",
    "r2 = r2_score(y_test, y_pts_pred_tuned_knn)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression (Randomized Search)\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Randomized Search took {elapsed_time_rounded} seconds.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
