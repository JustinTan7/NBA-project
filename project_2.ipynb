{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Preparing and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data set length: 31550 rows\n",
      "Length of data set after dropping the 2024 season: 31135 rows\n",
      "Length of data set after dropping all rows with less than 10 games played: 27308 rows\n",
      "Columns with missing data:\n",
      "Age      12\n",
      "GS     7706\n",
      "MP      939\n",
      "3P     5725\n",
      "3PA    5725\n",
      "3P%    8346\n",
      "2P%       1\n",
      "FT%      85\n",
      "ORB    4153\n",
      "DRB    4153\n",
      "TRB     769\n",
      "STL    4969\n",
      "BLK    4968\n",
      "TOV    5068\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Columns with missing data after filling:\n",
      "3P%    0\n",
      "2P%    0\n",
      "FT%    0\n",
      "Age    0\n",
      "GS     0\n",
      "MP     0\n",
      "3P     0\n",
      "3PA    0\n",
      "ORB    0\n",
      "DRB    0\n",
      "TRB    0\n",
      "STL    0\n",
      "BLK    0\n",
      "TOV    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "nba_df = pd.read_csv('player_totals.csv', encoding = 'unicode_escape', engine ='python')\n",
    "\n",
    "print(f\"Original data set length: {len(nba_df)} rows\")\n",
    "\n",
    "season2024_condition = nba_df['Season'] > 2023\n",
    "nba_df.drop(index=nba_df[season2024_condition].index, inplace=True)\n",
    "\n",
    "# season2005_condition = nba_df['Season'] <= 2005\n",
    "# nba_df.drop(index=nba_df[season2005_condition].index, inplace=True)\n",
    "\n",
    "# targeting modern game\n",
    "\n",
    "print(f\"Length of data set after dropping the 2024 season: {len(nba_df)} rows\")\n",
    "\n",
    "gp_condition = nba_df[\"GP\"] <= 10\n",
    "nba_df.drop(index=nba_df[gp_condition].index, inplace=True)\n",
    "\n",
    "print(f\"Length of data set after dropping all rows with less than 10 games played: {len(nba_df)} rows\")\n",
    "\n",
    "# nba_df = nba_df.dropna()\n",
    "\n",
    "# print(f\"Length of data set after dropping all rows with NA values: {len(nba_df)} rows\")\n",
    "\n",
    "missing_data = nba_df.isnull().sum()\n",
    "\n",
    "print(\"Columns with missing data:\")\n",
    "print(missing_data[missing_data > 0])\n",
    "print(\"\\n\")\n",
    "\n",
    "columns_to_fill = ['3P%', '2P%', 'FT%', 'Age', 'GS', 'MP', '3P', '3PA', 'ORB', 'DRB', 'TRB', 'STL', 'BLK', 'TOV']\n",
    "\n",
    "nba_df[columns_to_fill] = nba_df[columns_to_fill].fillna(0)\n",
    "\n",
    "missing_data_updated = nba_df[columns_to_fill].isnull().sum()\n",
    "\n",
    "print('Columns with missing data after filling:')\n",
    "print(missing_data_updated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Linear Regression and Cross-Validation:\n",
      "MSE: 3057.3544741968035\n",
      "MAE: 36.514456396036174\n",
      "R-squared: 0.9869317159981545\n",
      "Adjusted R-squared: 0.9869283651561028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Extract features and target variable\n",
    "X = nba_df[[\"GP\", \"MP\", \"FG%\", \"3P%\", \"2P%\", \"FT%\", \"FG\"]]\n",
    "y_pts = nba_df[\"PTS\"]\n",
    "\n",
    "# Create and fit the scaler on the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Create KFold cross-validator\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=13)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_mse_pts = cross_val_score(model, X_scaled, y_pts, cv=kf, scoring='neg_mean_squared_error')\n",
    "cv_mae_pts = cross_val_score(model, X_scaled, y_pts, cv=kf, scoring='neg_mean_absolute_error')\n",
    "cv_r2_pts = cross_val_score(model, X_scaled, y_pts, cv=kf, scoring='r2')\n",
    "\n",
    "# Calculate mean values of metrics\n",
    "mse_pts_mean = -np.mean(cv_mse_pts)\n",
    "mae_pts_mean = -np.mean(cv_mae_pts)\n",
    "r2_pts_mean = np.mean(cv_r2_pts)\n",
    "\n",
    "# Calculate adjusted R-squared\n",
    "n = len(y_pts)\n",
    "k = X.shape[1]\n",
    "adjusted_r2_pts = 1 - ((1 - r2_pts_mean) * (n - 1) / (n - k - 1))\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Linear Regression and Cross-Validation:\")\n",
    "print(f\"MSE: {mse_pts_mean}\")\n",
    "print(f\"MAE: {mae_pts_mean}\")\n",
    "print(f\"R-squared: {r2_pts_mean}\")\n",
    "print(f\"Adjusted R-squared: {adjusted_r2_pts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Justification\n",
    "The choice to use linear regression was due to the fact that the relationship between the features and the target variable was linear. So any changes to one of them would affect the outcome of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Untuned Random Forest Model:\n",
      "MSE: 26552.490437486267\n",
      "MAE: 104.67685005492496\n",
      "R-squared: 0.886211854636577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing set\n",
    "X_train, X_test, y_pts_train, y_pts_test = train_test_split(\n",
    "    X, y_pts, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# Create and fit the scaler on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Random Forest regression model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model to the scaled data\n",
    "rf_model.fit(X_train_scaled, y_pts_train)\n",
    "\n",
    "# Predictions on scaled data\n",
    "y_pts_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation for Points (PTS) with untuned Random Forest model and scaling\n",
    "mse_pts_rf = mean_squared_error(y_pts_test, y_pts_pred_rf)\n",
    "mae_pts_rf = mean_absolute_error(y_pts_test, y_pts_pred_rf)\n",
    "r2_pts_rf = r2_score(y_pts_test, y_pts_pred_rf)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Untuned Random Forest Model:\")\n",
    "print(f\"MSE: {mse_pts_rf}\")\n",
    "print(f\"MAE: {mae_pts_rf}\")\n",
    "print(f\"R-squared: {r2_pts_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Retraining with Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "1080 fits failed out of a total of 4320.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "747 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "333 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [           nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan -2967.79525213\n",
      " -2933.92365005 -2912.49238253 -3086.30483978 -3035.69260701\n",
      " -2976.72162832 -3183.98065871 -3151.12583281 -3115.62395831\n",
      " -3080.39095049 -3020.04839581 -2990.33369435 -3048.98687581\n",
      " -3026.77563344 -3014.04594504 -3241.47536263 -3197.89005718\n",
      " -3136.68557755 -3224.31102444 -3210.06931391 -3200.35748464\n",
      " -3224.31102444 -3210.06931391 -3200.35748464 -3251.1312188\n",
      " -3242.54745824 -3228.11016731 -2967.79525213 -2933.92365005\n",
      " -2912.49238253 -3086.30483978 -3035.69260701 -2976.72162832\n",
      " -3183.98065871 -3151.12583281 -3115.62395831 -3080.39095049\n",
      " -3020.04839581 -2990.33369435 -3048.98687581 -3026.77563344\n",
      " -3014.04594504 -3241.47536263 -3197.89005718 -3136.68557755\n",
      " -3224.31102444 -3210.06931391 -3200.35748464 -3224.31102444\n",
      " -3210.06931391 -3200.35748464 -3251.1312188  -3242.54745824\n",
      " -3228.11016731 -2580.85546772 -2558.11197431 -2549.12785267\n",
      " -2575.28595039 -2557.44245274 -2549.83934269 -2583.80648708\n",
      " -2567.05756644 -2555.5503284  -2574.03117029 -2562.58582056\n",
      " -2554.02207401 -2575.00806341 -2562.80827749 -2555.14151366\n",
      " -2578.39073152 -2568.71399081 -2557.43617041 -2594.43326493\n",
      " -2585.61599447 -2574.11382703 -2594.43326493 -2585.61599447\n",
      " -2574.11382703 -2597.31388268 -2589.28749566 -2577.84443493\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan -3693.16223069\n",
      " -3623.08325385 -3553.97325587 -3540.92326414 -3547.4349229\n",
      " -3583.11471823 -3648.22449257 -3716.00711914 -3709.70588043\n",
      " -3523.20385219 -3618.512381   -3627.14674682 -3540.53307474\n",
      " -3575.10160741 -3587.89939387 -3603.73265245 -3683.82964793\n",
      " -3665.36942586 -3705.63732172 -3728.43785906 -3699.62232257\n",
      " -3705.63732172 -3728.43785906 -3699.62232257 -3667.3529236\n",
      " -3660.71713273 -3706.66217598 -3693.16223069 -3623.08325385\n",
      " -3553.97325587 -3540.92326414 -3547.4349229  -3583.11471823\n",
      " -3648.22449257 -3716.00711914 -3709.70588043 -3523.20385219\n",
      " -3618.512381   -3627.14674682 -3540.53307474 -3575.10160741\n",
      " -3587.89939387 -3603.73265245 -3683.82964793 -3665.36942586\n",
      " -3705.63732172 -3728.43785906 -3699.62232257 -3705.63732172\n",
      " -3728.43785906 -3699.62232257 -3667.3529236  -3660.71713273\n",
      " -3706.66217598 -2581.97178943 -2567.6582528  -2560.58683425\n",
      " -2579.89039834 -2570.50164009 -2563.63495926 -2599.28082433\n",
      " -2589.69301098 -2580.19476413 -2583.09255286 -2574.92006792\n",
      " -2568.20178784 -2585.75710768 -2577.46507183 -2570.43746853\n",
      " -2596.87107173 -2590.00842433 -2580.91350264 -2607.91180105\n",
      " -2600.93504262 -2592.37931382 -2607.91180105 -2600.93504262\n",
      " -2592.37931382 -2612.32452006 -2606.97435901 -2598.26282774\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan -3006.36148829\n",
      " -2955.37925917 -2928.43660052 -3057.69359944 -2989.90246238\n",
      " -2975.99199174 -3201.40906009 -3139.60724594 -3118.99397693\n",
      " -3104.6903993  -3060.81325866 -3033.21990923 -3058.31783238\n",
      " -3027.63984351 -2990.09661443 -3238.86362726 -3174.59787077\n",
      " -3140.24834222 -3257.89416512 -3213.05970017 -3191.3793274\n",
      " -3257.89416512 -3213.05970017 -3191.3793274  -3286.76791851\n",
      " -3259.85844198 -3248.29969064 -3006.36148829 -2955.37925917\n",
      " -2928.43660052 -3057.69359944 -2989.90246238 -2975.99199174\n",
      " -3201.40906009 -3139.60724594 -3118.99397693 -3104.6903993\n",
      " -3060.81325866 -3033.21990923 -3058.31783238 -3027.63984351\n",
      " -2990.09661443 -3238.86362726 -3174.59787077 -3140.24834222\n",
      " -3257.89416512 -3213.05970017 -3191.3793274  -3257.89416512\n",
      " -3213.05970017 -3191.3793274  -3286.76791851 -3259.85844198\n",
      " -3248.29969064 -2577.90167499 -2558.56255981 -2549.06836804\n",
      " -2585.60168701 -2559.87975582 -2548.97291167 -2587.48030235\n",
      " -2572.05257169 -2558.57900663 -2575.45671006 -2564.98334346\n",
      " -2554.15471147 -2578.31305345 -2566.66201486 -2557.58150845\n",
      " -2581.24708215 -2568.20550068 -2557.26811156 -2593.94788497\n",
      " -2585.20863891 -2573.98529252 -2593.94788497 -2585.20863891\n",
      " -2573.98529252 -2597.33877694 -2589.48909096 -2577.92110941\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan -2993.49742892\n",
      " -2941.2200608  -2914.65132828 -3089.2610015  -3036.12145949\n",
      " -2976.70855641 -3180.35534492 -3149.20354257 -3114.74796401\n",
      " -3080.39095049 -3020.04839581 -2991.38730716 -3048.98687581\n",
      " -3026.23860793 -3013.66273992 -3241.47536263 -3197.89005718\n",
      " -3136.68557755 -3224.31102444 -3210.06931391 -3200.35748464\n",
      " -3224.31102444 -3210.06931391 -3200.35748464 -3251.1312188\n",
      " -3242.54745824 -3228.11016731 -2993.49742892 -2941.2200608\n",
      " -2914.65132828 -3089.2610015  -3036.12145949 -2976.70855641\n",
      " -3180.35534492 -3149.20354257 -3114.74796401 -3080.39095049\n",
      " -3020.04839581 -2991.38730716 -3048.98687581 -3026.23860793\n",
      " -3013.66273992 -3241.47536263 -3197.89005718 -3136.68557755\n",
      " -3224.31102444 -3210.06931391 -3200.35748464 -3224.31102444\n",
      " -3210.06931391 -3200.35748464 -3251.1312188  -3242.54745824\n",
      " -3228.11016731 -2581.89854734 -2559.60315868 -2550.16141882\n",
      " -2575.35458306 -2557.34783045 -2549.88454566 -2583.80648708\n",
      " -2567.05756644 -2555.5503284  -2574.0874602  -2562.5991831\n",
      " -2554.05254967 -2575.00806341 -2562.80827749 -2555.10249268\n",
      " -2578.39073152 -2568.71399081 -2557.43617041 -2594.43326493\n",
      " -2585.61599447 -2574.11382703 -2594.43326493 -2585.61599447\n",
      " -2574.11382703 -2597.31388268 -2589.28749566 -2577.84443493\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan -2884.84566819\n",
      " -2858.76323886 -2833.34399751 -2947.10120955 -2896.56587812\n",
      " -2869.59817055 -2969.51486398 -2938.39093707 -2955.1480059\n",
      " -2976.32445939 -2918.98962251 -2887.25678713 -2977.93932562\n",
      " -2928.21281698 -2904.90884686 -2996.0177013  -2999.33979453\n",
      " -2982.22306542 -3098.40119454 -3055.23146226 -3028.93578862\n",
      " -3098.40119454 -3055.23146226 -3028.93578862 -3110.0754821\n",
      " -3074.09721082 -3081.41824513 -2884.84566819 -2858.76323886\n",
      " -2833.34399751 -2947.10120955 -2896.56587812 -2869.59817055\n",
      " -2969.51486398 -2938.39093707 -2955.1480059  -2976.32445939\n",
      " -2918.98962251 -2887.25678713 -2977.93932562 -2928.21281698\n",
      " -2904.90884686 -2996.0177013  -2999.33979453 -2982.22306542\n",
      " -3098.40119454 -3055.23146226 -3028.93578862 -3098.40119454\n",
      " -3055.23146226 -3028.93578862 -3110.0754821  -3074.09721082\n",
      " -3081.41824513 -4775.76551247 -4771.14721614 -4768.15752322\n",
      " -4646.05190935 -4645.57366223 -4643.80950544 -4241.68450013\n",
      " -4242.80256793 -4241.08464698 -4628.76598383 -4629.14577575\n",
      " -4626.42249486 -4564.09654857 -4562.52621587 -4560.80073136\n",
      " -4148.79674505 -4148.1837168  -4148.38083794 -4000.15504379\n",
      " -3999.66571648 -3999.30076472 -4000.15504379 -3999.66571648\n",
      " -3999.30076472 -3910.19688077 -3910.30730277 -3910.40651211\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan -3518.96515608\n",
      " -3484.13688578 -3483.68691714 -3477.13163258 -3485.05327722\n",
      " -3507.71933631 -3559.22467581 -3635.08049344 -3586.45349547\n",
      " -3461.9684007  -3569.67775016 -3568.33512939 -3556.11237938\n",
      " -3530.35458035 -3524.7102447  -3656.78759332 -3665.96542718\n",
      " -3615.39444798 -3520.72034757 -3569.02973398 -3549.15486924\n",
      " -3520.72034757 -3569.02973398 -3549.15486924 -3601.28013724\n",
      " -3611.22433259 -3584.47128237 -3518.96515608 -3484.13688578\n",
      " -3483.68691714 -3477.13163258 -3485.05327722 -3507.71933631\n",
      " -3559.22467581 -3635.08049344 -3586.45349547 -3461.9684007\n",
      " -3569.67775016 -3568.33512939 -3556.11237938 -3530.35458035\n",
      " -3524.7102447  -3656.78759332 -3665.96542718 -3615.39444798\n",
      " -3520.72034757 -3569.02973398 -3549.15486924 -3520.72034757\n",
      " -3569.02973398 -3549.15486924 -3601.28013724 -3611.22433259\n",
      " -3584.47128237 -3638.88495783 -3639.15368239 -3637.34465011\n",
      " -3630.08244365 -3633.10959413 -3634.4782959  -3570.5949647\n",
      " -3570.31935107 -3569.94721317 -3636.08730114 -3636.58955991\n",
      " -3636.02234897 -3628.04586773 -3628.31142735 -3628.26705354\n",
      " -3569.70985723 -3569.74654924 -3570.16410726 -3489.79462911\n",
      " -3489.81668917 -3489.86039519 -3489.79462911 -3489.81668917\n",
      " -3489.86039519 -3474.18612229 -3473.9809403  -3473.86649568\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan -2921.69723204\n",
      " -2859.25800775 -2829.43317344 -2929.92289322 -2854.5429458\n",
      " -2845.02697696 -3020.85990986 -2978.33862513 -2969.52871623\n",
      " -2896.56428418 -2906.48995222 -2883.51022517 -2977.03557593\n",
      " -2939.15293034 -2905.39015461 -3024.74476932 -3006.6818778\n",
      " -2989.3773166  -3036.48914547 -3031.06661693 -3043.08919662\n",
      " -3036.48914547 -3031.06661693 -3043.08919662 -3122.84317992\n",
      " -3113.46669067 -3073.57174815 -2921.69723204 -2859.25800775\n",
      " -2829.43317344 -2929.92289322 -2854.5429458  -2845.02697696\n",
      " -3020.85990986 -2978.33862513 -2969.52871623 -2896.56428418\n",
      " -2906.48995222 -2883.51022517 -2977.03557593 -2939.15293034\n",
      " -2905.39015461 -3024.74476932 -3006.6818778  -2989.3773166\n",
      " -3036.48914547 -3031.06661693 -3043.08919662 -3036.48914547\n",
      " -3031.06661693 -3043.08919662 -3122.84317992 -3113.46669067\n",
      " -3073.57174815 -4761.62180842 -4759.99283992 -4759.87370121\n",
      " -4635.31223326 -4634.59668209 -4634.37804279 -4237.17780474\n",
      " -4239.50022205 -4238.83730627 -4620.53727844 -4620.75294804\n",
      " -4619.77952826 -4552.23226843 -4551.52404008 -4551.90093903\n",
      " -4146.83092349 -4146.44676344 -4146.88887205 -4000.32769692\n",
      " -3999.59318031 -3999.26957503 -4000.32769692 -3999.59318031\n",
      " -3999.26957503 -3910.21105104 -3910.36332661 -3910.17019704\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan            nan\n",
      "            nan            nan            nan -2915.37790062\n",
      " -2878.79347628 -2838.64491873 -2941.62431173 -2890.36018351\n",
      " -2863.92418229 -2966.80967651 -2939.77721375 -2954.67057444\n",
      " -2980.02397212 -2919.02046643 -2887.41998595 -2975.36609758\n",
      " -2926.33367339 -2905.71597762 -2996.0177013  -2999.33979453\n",
      " -2982.05889958 -3098.40119454 -3055.23146226 -3028.93578862\n",
      " -3098.40119454 -3055.23146226 -3028.93578862 -3110.0754821\n",
      " -3074.09721082 -3081.41824513 -2915.37790062 -2878.79347628\n",
      " -2838.64491873 -2941.62431173 -2890.36018351 -2863.92418229\n",
      " -2966.80967651 -2939.77721375 -2954.67057444 -2980.02397212\n",
      " -2919.02046643 -2887.41998595 -2975.36609758 -2926.33367339\n",
      " -2905.71597762 -2996.0177013  -2999.33979453 -2982.05889958\n",
      " -3098.40119454 -3055.23146226 -3028.93578862 -3098.40119454\n",
      " -3055.23146226 -3028.93578862 -3110.0754821  -3074.09721082\n",
      " -3081.41824513 -4780.11033393 -4772.42573097 -4769.41167514\n",
      " -4646.05190935 -4645.57366223 -4643.80950544 -4241.68450013\n",
      " -4242.80256793 -4241.08464698 -4628.76598383 -4629.14577575\n",
      " -4626.42249486 -4564.09654857 -4562.52621587 -4560.80073136\n",
      " -4148.79674505 -4148.1837168  -4148.38083794 -4000.15504379\n",
      " -3999.66571648 -3999.30076472 -4000.15504379 -3999.66571648\n",
      " -3999.30076472 -3910.19688077 -3910.30730277 -3910.40651211]\n",
      "  warnings.warn(\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [            nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -4.59044952e+02\n",
      " -4.30222297e+02 -4.13551582e+02 -7.91290733e+02 -7.62915209e+02\n",
      " -7.39948537e+02 -1.31442104e+03 -1.29320065e+03 -1.27360226e+03\n",
      " -9.21448242e+02 -8.90731093e+02 -8.74083549e+02 -9.95703033e+02\n",
      " -9.76694975e+02 -9.58779026e+02 -1.45374479e+03 -1.43675569e+03\n",
      " -1.41807917e+03 -1.62698367e+03 -1.61016242e+03 -1.60310827e+03\n",
      " -1.62698367e+03 -1.61016242e+03 -1.60310827e+03 -1.72064086e+03\n",
      " -1.70449461e+03 -1.69707738e+03 -4.59044952e+02 -4.30222297e+02\n",
      " -4.13551582e+02 -7.91290733e+02 -7.62915209e+02 -7.39948537e+02\n",
      " -1.31442104e+03 -1.29320065e+03 -1.27360226e+03 -9.21448242e+02\n",
      " -8.90731093e+02 -8.74083549e+02 -9.95703033e+02 -9.76694975e+02\n",
      " -9.58779026e+02 -1.45374479e+03 -1.43675569e+03 -1.41807917e+03\n",
      " -1.62698367e+03 -1.61016242e+03 -1.60310827e+03 -1.62698367e+03\n",
      " -1.61016242e+03 -1.60310827e+03 -1.72064086e+03 -1.70449461e+03\n",
      " -1.69707738e+03 -3.77594290e+02 -3.61527749e+02 -3.54170321e+02\n",
      " -5.31523771e+02 -5.16270868e+02 -5.09574467e+02 -8.69277110e+02\n",
      " -8.56240980e+02 -8.49173245e+02 -5.81760543e+02 -5.68469853e+02\n",
      " -5.62138876e+02 -6.43188054e+02 -6.29929475e+02 -6.23888200e+02\n",
      " -9.65403365e+02 -9.54235418e+02 -9.47317856e+02 -1.05761887e+03\n",
      " -1.04440520e+03 -1.03927903e+03 -1.05761887e+03 -1.04440520e+03\n",
      " -1.03927903e+03 -1.14897168e+03 -1.13792689e+03 -1.13208124e+03\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -2.23226837e+03\n",
      " -2.20597008e+03 -2.16533551e+03 -2.24711291e+03 -2.24128234e+03\n",
      " -2.24379068e+03 -2.39424344e+03 -2.43992236e+03 -2.42665588e+03\n",
      " -2.23326622e+03 -2.27539910e+03 -2.27950174e+03 -2.25843063e+03\n",
      " -2.29945646e+03 -2.29340010e+03 -2.42578472e+03 -2.47181985e+03\n",
      " -2.45714624e+03 -2.52051212e+03 -2.53588359e+03 -2.51718884e+03\n",
      " -2.52051212e+03 -2.53588359e+03 -2.51718884e+03 -2.52031893e+03\n",
      " -2.52591117e+03 -2.55306784e+03 -2.23226837e+03 -2.20597008e+03\n",
      " -2.16533551e+03 -2.24711291e+03 -2.24128234e+03 -2.24379068e+03\n",
      " -2.39424344e+03 -2.43992236e+03 -2.42665588e+03 -2.23326622e+03\n",
      " -2.27539910e+03 -2.27950174e+03 -2.25843063e+03 -2.29945646e+03\n",
      " -2.29340010e+03 -2.42578472e+03 -2.47181985e+03 -2.45714624e+03\n",
      " -2.52051212e+03 -2.53588359e+03 -2.51718884e+03 -2.52051212e+03\n",
      " -2.53588359e+03 -2.51718884e+03 -2.52031893e+03 -2.52591117e+03\n",
      " -2.55306784e+03 -1.27903291e+03 -1.26986239e+03 -1.26513847e+03\n",
      " -1.31929087e+03 -1.30954633e+03 -1.30493895e+03 -1.42716834e+03\n",
      " -1.41926535e+03 -1.41452431e+03 -1.33023739e+03 -1.32252252e+03\n",
      " -1.31818291e+03 -1.34736678e+03 -1.33957047e+03 -1.33564035e+03\n",
      " -1.45453546e+03 -1.44770306e+03 -1.44302517e+03 -1.49130547e+03\n",
      " -1.48127584e+03 -1.47688727e+03 -1.49130547e+03 -1.48127584e+03\n",
      " -1.47688727e+03 -1.52879823e+03 -1.51974909e+03 -1.51448278e+03\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -4.73531348e+02\n",
      " -4.45034628e+02 -4.27062708e+02 -7.95182699e+02 -7.57408398e+02\n",
      " -7.41739939e+02 -1.32856508e+03 -1.29508543e+03 -1.27624871e+03\n",
      " -9.30451067e+02 -9.01238613e+02 -8.85076810e+02 -1.00426375e+03\n",
      " -9.82617234e+02 -9.63854334e+02 -1.46794196e+03 -1.43256057e+03\n",
      " -1.42403268e+03 -1.64058760e+03 -1.61497514e+03 -1.59714145e+03\n",
      " -1.64058760e+03 -1.61497514e+03 -1.59714145e+03 -1.73814753e+03\n",
      " -1.71136817e+03 -1.70737122e+03 -4.73531348e+02 -4.45034628e+02\n",
      " -4.27062708e+02 -7.95182699e+02 -7.57408398e+02 -7.41739939e+02\n",
      " -1.32856508e+03 -1.29508543e+03 -1.27624871e+03 -9.30451067e+02\n",
      " -9.01238613e+02 -8.85076810e+02 -1.00426375e+03 -9.82617234e+02\n",
      " -9.63854334e+02 -1.46794196e+03 -1.43256057e+03 -1.42403268e+03\n",
      " -1.64058760e+03 -1.61497514e+03 -1.59714145e+03 -1.64058760e+03\n",
      " -1.61497514e+03 -1.59714145e+03 -1.73814753e+03 -1.71136817e+03\n",
      " -1.70737122e+03 -3.80409800e+02 -3.64597387e+02 -3.56861290e+02\n",
      " -5.34540891e+02 -5.19007138e+02 -5.11775529e+02 -8.70172793e+02\n",
      " -8.56475564e+02 -8.50005281e+02 -5.82943346e+02 -5.69544920e+02\n",
      " -5.63282716e+02 -6.43582491e+02 -6.30935070e+02 -6.24673436e+02\n",
      " -9.65856446e+02 -9.54615177e+02 -9.47706757e+02 -1.05768379e+03\n",
      " -1.04445627e+03 -1.03930494e+03 -1.05768379e+03 -1.04445627e+03\n",
      " -1.03930494e+03 -1.14894251e+03 -1.13790765e+03 -1.13208494e+03\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -4.64728718e+02\n",
      " -4.33669052e+02 -4.14853351e+02 -7.91729600e+02 -7.62862348e+02\n",
      " -7.39760536e+02 -1.31261236e+03 -1.29229302e+03 -1.27317303e+03\n",
      " -9.21448242e+02 -8.90731093e+02 -8.74359554e+02 -9.95703033e+02\n",
      " -9.76641643e+02 -9.58701110e+02 -1.45374479e+03 -1.43675569e+03\n",
      " -1.41807917e+03 -1.62698367e+03 -1.61016242e+03 -1.60310827e+03\n",
      " -1.62698367e+03 -1.61016242e+03 -1.60310827e+03 -1.72064086e+03\n",
      " -1.70449461e+03 -1.69707738e+03 -4.64728718e+02 -4.33669052e+02\n",
      " -4.14853351e+02 -7.91729600e+02 -7.62862348e+02 -7.39760536e+02\n",
      " -1.31261236e+03 -1.29229302e+03 -1.27317303e+03 -9.21448242e+02\n",
      " -8.90731093e+02 -8.74359554e+02 -9.95703033e+02 -9.76641643e+02\n",
      " -9.58701110e+02 -1.45374479e+03 -1.43675569e+03 -1.41807917e+03\n",
      " -1.62698367e+03 -1.61016242e+03 -1.60310827e+03 -1.62698367e+03\n",
      " -1.61016242e+03 -1.60310827e+03 -1.72064086e+03 -1.70449461e+03\n",
      " -1.69707738e+03 -3.77711404e+02 -3.61555391e+02 -3.54204283e+02\n",
      " -5.31480433e+02 -5.16249643e+02 -5.09563902e+02 -8.69277110e+02\n",
      " -8.56240980e+02 -8.49173245e+02 -5.81778499e+02 -5.68477350e+02\n",
      " -5.62139416e+02 -6.43188054e+02 -6.29929475e+02 -6.23895809e+02\n",
      " -9.65403365e+02 -9.54235418e+02 -9.47317856e+02 -1.05761887e+03\n",
      " -1.04440520e+03 -1.03927903e+03 -1.05761887e+03 -1.04440520e+03\n",
      " -1.03927903e+03 -1.14897168e+03 -1.13792689e+03 -1.13208124e+03\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -5.55400388e-05\n",
      " -3.83537506e-05 -1.81683490e-05 -1.19998279e+02 -1.13452963e+02\n",
      " -1.10465678e+02 -5.27139132e+02 -5.18608526e+02 -5.12710633e+02\n",
      " -2.10025676e+02 -2.00365767e+02 -1.95822229e+02 -2.74242730e+02\n",
      " -2.65480202e+02 -2.60072900e+02 -6.79573862e+02 -6.72804976e+02\n",
      " -6.66008781e+02 -8.61917553e+02 -8.43819563e+02 -8.32357574e+02\n",
      " -8.61917553e+02 -8.43819563e+02 -8.32357574e+02 -9.66267442e+02\n",
      " -9.51757020e+02 -9.43941291e+02 -5.55400388e-05 -3.83537506e-05\n",
      " -1.81683490e-05 -1.19998279e+02 -1.13452963e+02 -1.10465678e+02\n",
      " -5.27139132e+02 -5.18608526e+02 -5.12710633e+02 -2.10025676e+02\n",
      " -2.00365767e+02 -1.95822229e+02 -2.74242730e+02 -2.65480202e+02\n",
      " -2.60072900e+02 -6.79573862e+02 -6.72804976e+02 -6.66008781e+02\n",
      " -8.61917553e+02 -8.43819563e+02 -8.32357574e+02 -8.61917553e+02\n",
      " -8.43819563e+02 -8.32357574e+02 -9.66267442e+02 -9.51757020e+02\n",
      " -9.43941291e+02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -2.55286695e+02 -2.55285995e+02 -2.55288105e+02 -7.58735125e+02\n",
      " -7.58726028e+02 -7.58721016e+02 -3.05626536e+02 -3.05599284e+02\n",
      " -3.05575064e+02 -3.99505149e+02 -3.99491454e+02 -3.99482872e+02\n",
      " -8.75497858e+02 -8.75472640e+02 -8.75479628e+02 -9.78525715e+02\n",
      " -9.78511573e+02 -9.78508524e+02 -9.78525715e+02 -9.78511573e+02\n",
      " -9.78508524e+02 -1.09288797e+03 -1.09286347e+03 -1.09286674e+03\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -1.83677022e+03\n",
      " -1.83043215e+03 -1.82803150e+03 -1.80975942e+03 -1.85074368e+03\n",
      " -1.86386545e+03 -2.00894346e+03 -2.04751949e+03 -2.02562996e+03\n",
      " -1.87011762e+03 -1.93386985e+03 -1.93191524e+03 -1.92079730e+03\n",
      " -1.90968481e+03 -1.91114752e+03 -2.11549617e+03 -2.10315048e+03\n",
      " -2.07670323e+03 -2.04820012e+03 -2.09768064e+03 -2.08263225e+03\n",
      " -2.04820012e+03 -2.09768064e+03 -2.08263225e+03 -2.12745160e+03\n",
      " -2.14980578e+03 -2.12977238e+03 -1.83677022e+03 -1.83043215e+03\n",
      " -1.82803150e+03 -1.80975942e+03 -1.85074368e+03 -1.86386545e+03\n",
      " -2.00894346e+03 -2.04751949e+03 -2.02562996e+03 -1.87011762e+03\n",
      " -1.93386985e+03 -1.93191524e+03 -1.92079730e+03 -1.90968481e+03\n",
      " -1.91114752e+03 -2.11549617e+03 -2.10315048e+03 -2.07670323e+03\n",
      " -2.04820012e+03 -2.09768064e+03 -2.08263225e+03 -2.04820012e+03\n",
      " -2.09768064e+03 -2.08263225e+03 -2.12745160e+03 -2.14980578e+03\n",
      " -2.12977238e+03 -1.53893907e+03 -1.53893837e+03 -1.53894244e+03\n",
      " -1.57183515e+03 -1.57183515e+03 -1.57183515e+03 -1.67981406e+03\n",
      " -1.67981406e+03 -1.67981406e+03 -1.58432114e+03 -1.58431793e+03\n",
      " -1.58431873e+03 -1.60155473e+03 -1.60155422e+03 -1.60155315e+03\n",
      " -1.70968053e+03 -1.70968071e+03 -1.70968055e+03 -1.71917816e+03\n",
      " -1.71917759e+03 -1.71917742e+03 -1.71917816e+03 -1.71917759e+03\n",
      " -1.71917742e+03 -1.75200828e+03 -1.75200825e+03 -1.75200821e+03\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -3.26484237e+00\n",
      " -2.84112918e+00 -2.50716994e+00 -1.30413520e+02 -1.23842782e+02\n",
      " -1.20583841e+02 -5.38952550e+02 -5.27684750e+02 -5.21383812e+02\n",
      " -2.12179615e+02 -2.06424808e+02 -1.99655627e+02 -2.81012863e+02\n",
      " -2.74359348e+02 -2.66335202e+02 -6.91303018e+02 -6.78083523e+02\n",
      " -6.72608451e+02 -8.57983367e+02 -8.47231724e+02 -8.38977719e+02\n",
      " -8.57983367e+02 -8.47231724e+02 -8.38977719e+02 -9.69070140e+02\n",
      " -9.61319985e+02 -9.46783591e+02 -3.26484237e+00 -2.84112918e+00\n",
      " -2.50716994e+00 -1.30413520e+02 -1.23842782e+02 -1.20583841e+02\n",
      " -5.38952550e+02 -5.27684750e+02 -5.21383812e+02 -2.12179615e+02\n",
      " -2.06424808e+02 -1.99655627e+02 -2.81012863e+02 -2.74359348e+02\n",
      " -2.66335202e+02 -6.91303018e+02 -6.78083523e+02 -6.72608451e+02\n",
      " -8.57983367e+02 -8.47231724e+02 -8.38977719e+02 -8.57983367e+02\n",
      " -8.47231724e+02 -8.38977719e+02 -9.69070140e+02 -9.61319985e+02\n",
      " -9.46783591e+02 -1.40200642e+01 -1.40203659e+01 -1.40197356e+01\n",
      " -2.64598405e+02 -2.64594679e+02 -2.64595236e+02 -7.62496617e+02\n",
      " -7.62494688e+02 -7.62493125e+02 -3.12716944e+02 -3.12709663e+02\n",
      " -3.12705953e+02 -4.05369920e+02 -4.05372009e+02 -4.05359158e+02\n",
      " -8.77876848e+02 -8.77853515e+02 -8.77843027e+02 -9.78986354e+02\n",
      " -9.78983367e+02 -9.78976991e+02 -9.78986354e+02 -9.78983367e+02\n",
      " -9.78976991e+02 -1.09326674e+03 -1.09325463e+03 -1.09323708e+03\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan -3.87373232e-04\n",
      " -2.21307494e-04 -1.05385577e-04 -1.20520772e+02 -1.13881792e+02\n",
      " -1.10599238e+02 -5.27053723e+02 -5.18895383e+02 -5.12540465e+02\n",
      " -2.09944928e+02 -2.00305068e+02 -1.95774594e+02 -2.74194268e+02\n",
      " -2.65217164e+02 -2.60144650e+02 -6.79573862e+02 -6.72804976e+02\n",
      " -6.65820559e+02 -8.61917553e+02 -8.43819563e+02 -8.32357574e+02\n",
      " -8.61917553e+02 -8.43819563e+02 -8.32357574e+02 -9.66267442e+02\n",
      " -9.51757020e+02 -9.43941291e+02 -3.87373232e-04 -2.21307494e-04\n",
      " -1.05385577e-04 -1.20520772e+02 -1.13881792e+02 -1.10599238e+02\n",
      " -5.27053723e+02 -5.18895383e+02 -5.12540465e+02 -2.09944928e+02\n",
      " -2.00305068e+02 -1.95774594e+02 -2.74194268e+02 -2.65217164e+02\n",
      " -2.60144650e+02 -6.79573862e+02 -6.72804976e+02 -6.65820559e+02\n",
      " -8.61917553e+02 -8.43819563e+02 -8.32357574e+02 -8.61917553e+02\n",
      " -8.43819563e+02 -8.32357574e+02 -9.66267442e+02 -9.51757020e+02\n",
      " -9.43941291e+02 -9.15488928e-05 -9.15488928e-05 -9.15488928e-05\n",
      " -2.55286695e+02 -2.55285995e+02 -2.55288105e+02 -7.58735125e+02\n",
      " -7.58726028e+02 -7.58721016e+02 -3.05626536e+02 -3.05599284e+02\n",
      " -3.05575064e+02 -3.99505149e+02 -3.99491454e+02 -3.99482872e+02\n",
      " -8.75497858e+02 -8.75472640e+02 -8.75479628e+02 -9.78525715e+02\n",
      " -9.78511573e+02 -9.78508524e+02 -9.78525715e+02 -9.78511573e+02\n",
      " -9.78508524e+02 -1.09288797e+03 -1.09286347e+03 -1.09286674e+03]\n",
      "  warnings.warn(\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\justi\\Documents\\NBA-project\\project_2.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/justi/Documents/NBA-project/project_2.ipynb#X11sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m X_train, X_test \u001b[39m=\u001b[39m X_scaled[train_index], X_scaled[test_index]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/justi/Documents/NBA-project/project_2.ipynb#X11sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m y_train, y_test \u001b[39m=\u001b[39m y_pts\u001b[39m.\u001b[39miloc[train_index], y_pts\u001b[39m.\u001b[39miloc[test_index]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/justi/Documents/NBA-project/project_2.ipynb#X11sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m grid_search\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/justi/Documents/NBA-project/project_2.ipynb#X11sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# Monitor CPU and memory usage\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/justi/Documents/NBA-project/project_2.ipynb#X11sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m cpu_percentages\u001b[39m.\u001b[39mappend(psutil\u001b[39m.\u001b[39mcpu_percent())\n",
      "File \u001b[1;32mc:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\justi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\justi\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\justi\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39mresult(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\justi\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\justi\\anaconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "\n",
    "# Define a custom scorer for adjusted R-squared\n",
    "def adjusted_r2_scorer(estimator, X, y):\n",
    "    n = len(y)\n",
    "    k = X.shape[1]\n",
    "    r2 = r2_score(y, estimator.predict(X))\n",
    "    return 1 - (1 - r2) * (n - 1) / (n - k - 1)\n",
    "\n",
    "# Create the Random Forest regression model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    rf_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring={'neg_mean_squared_error': 'neg_mean_squared_error', 'adjusted_r2': make_scorer(adjusted_r2_scorer)},\n",
    "    refit='neg_mean_squared_error',  # Refit using neg_mean_squared_error for predictions\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Create and fit the scaler on the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Monitor CPU and memory usage during grid search\n",
    "cpu_percentages = []\n",
    "memory_percentages = []\n",
    "\n",
    "# Fit the model to the data and perform cross-validation\n",
    "for i, (train_index, test_index) in enumerate(grid_search.cv.split(X_scaled, y_pts)):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y_pts.iloc[train_index], y_pts.iloc[test_index]\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Monitor CPU and memory usage\n",
    "    cpu_percentages.append(psutil.cpu_percent())\n",
    "    memory_percentages.append(psutil.virtual_memory().percent)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Get the best hyperparameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a new Random Forest model with the best hyperparameters\n",
    "best_rf_model = RandomForestRegressor(random_state=42, **best_params).fit(X_scaled, y_pts)\n",
    "\n",
    "# Calculate adjusted R-squared for the best model\n",
    "best_rf_model_r2 = r2_score(y_pts, best_rf_model.predict(X_scaled))\n",
    "adjusted_r2 = 1 - (1 - best_rf_model_r2) * (len(y_pts) - 1) / (len(y_pts) - X_scaled.shape[1] - 1)\n",
    "\n",
    "# Predictions\n",
    "y_pts_pred_tuned_rf = best_rf_model.predict(X_scaled)\n",
    "\n",
    "# Evaluation for Points (PTS) with tuned Random Forest model\n",
    "mse_pts_tuned_rf = mean_squared_error(y_pts, y_pts_pred_tuned_rf)\n",
    "mae_pts_tuned_rf = mean_absolute_error(y_pts, y_pts_pred_tuned_rf)\n",
    "r2_pts_tuned_rf = best_rf_model_r2\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Grid Search Random Forest Regression Model (Cross-Validation):\")\n",
    "print(f\"MSE: {mse_pts_tuned_rf}\")\n",
    "print(f\"MAE: {mae_pts_tuned_rf}\")\n",
    "print(f\"R-squared: {r2_pts_tuned_rf}\")\n",
    "print(f\"Adjusted R-squared: {adjusted_r2}\")\n",
    "print(f\"Grid Search with Cross-Validation took {elapsed_time_rounded} seconds.\")\n",
    "\n",
    "# Print average CPU and memory usage during grid search\n",
    "print(f\"Average CPU Usage: {np.mean(cpu_percentages)}%\")\n",
    "print(f\"Average Memory Usage: {np.mean(memory_percentages)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Retraining with Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "15 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [-29549.62244193 -37383.55549316 -21785.17225305             nan\n",
      " -20934.98665907             nan             nan -31442.23007266\n",
      " -21246.46200204 -21040.23340186]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Randomized Search Random Forest Regression Model:\n",
      "MSE: 19752.866031005913\n",
      "MAE: 90.05895923429973\n",
      "R-squared: 0.8994674418860689\n",
      "Randomized Search took 11.45 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_pts_train, y_pts_test = train_test_split(\n",
    "    X, y_pts, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# Create and fit the scaler on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the hyperparameter grid for Random Forest\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Create the Random Forest regression model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "randomized_search = RandomizedSearchCV(rf_model, param_distributions=param_dist, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model to the data\n",
    "randomized_search.fit(X_train_scaled, y_pts_train)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = randomized_search.best_params_\n",
    "\n",
    "# Create a new Random Forest model with the best hyperparameters\n",
    "best_rf_model = RandomForestRegressor(random_state=42, **best_params).fit(X_train_scaled, y_pts_train)\n",
    "\n",
    "# Predictions\n",
    "y_pts_pred_tuned_rf = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation for Points (PTS) with tuned Random Forest model\n",
    "mse_pts_tuned_rf = mean_squared_error(y_pts_test, y_pts_pred_tuned_rf)\n",
    "mae_pts_tuned_rf = mean_absolute_error(y_pts_test, y_pts_pred_tuned_rf)\n",
    "r2_pts_tuned_rf = r2_score(y_pts_test, y_pts_pred_tuned_rf)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Randomized Search Random Forest Regression Model:\")\n",
    "print(f\"MSE: {mse_pts_tuned_rf}\")\n",
    "print(f\"MAE: {mae_pts_tuned_rf}\")\n",
    "print(f\"R-squared: {r2_pts_tuned_rf}\")\n",
    "\n",
    "print(f\"Randomized Search took {elapsed_time_rounded} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Untuned k-Nearest Neigbours Regression\n",
      "MSE: 31116.79576711827\n",
      "MAE: 115.98396191871107\n",
      "R-squared: 0.8666519628985883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X and y are your features and target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_pts, test_size=0.4, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create kNN regression model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors\n",
    "\n",
    "# Fit the model to the data\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Untuned k-Nearest Neigbours Regression\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Retraining with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression\n",
      "MSE: 22665.662973350594\n",
      "MAE: 99.85248456114738\n",
      "R-squared: 0.8846427107599278\n",
      "Grid Search took 8.9 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# Assuming X and y are your features and target variable\n",
    "X = nba_df[[\"GP\", \"MP\", \"FG%\", \"3P%\", \"2P%\", \"FT%\"]]\n",
    "y_pts = nba_df[\"PTS\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_pts, test_size=0.4, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "param_grid= {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': [20, 30, 40],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create kNN regression model\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(knn_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a new KNN model with the best hyperparameters\n",
    "best_knn_model = KNeighborsRegressor(**best_params).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pts_pred_tuned_knn = best_knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pts_pred_tuned_knn)\n",
    "mae = mean_absolute_error(y_test, y_pts_pred_tuned_knn)\n",
    "r2 = r2_score(y_test, y_pts_pred_tuned_knn)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Grid Search took {elapsed_time_rounded} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Retraining with Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression (Randomized Search)\n",
      "MSE: 22665.662973350594\n",
      "MAE: 99.85248456114738\n",
      "R-squared: 0.8846427107599278\n",
      "Randomized Search took 1.5 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Assuming X and y are your features and target variable\n",
    "X = nba_df[[\"GP\", \"MP\", \"FG%\", \"3P%\", \"2P%\", \"FT%\"]]\n",
    "y_pts = nba_df[\"PTS\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_pts, test_size=0.4, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "param_dist = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': [20, 30, 40],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create kNN regression model\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "random_search = RandomizedSearchCV(knn_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='neg_mean_squared_error', n_jobs=1, random_state=42)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model to the data\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Create a new KNN model with the best hyperparameters\n",
    "best_knn_model = KNeighborsRegressor(**best_params).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pts_pred_tuned_knn = best_knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pts_pred_tuned_knn)\n",
    "mae = mean_absolute_error(y_test, y_pts_pred_tuned_knn)\n",
    "r2 = r2_score(y_test, y_pts_pred_tuned_knn)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression (Randomized Search)\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Randomized Search took {elapsed_time_rounded} seconds.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
