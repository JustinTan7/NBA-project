{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Preparing and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data set length: 31550 rows\n",
      "Length of data set after dropping the 2024 season: 31135 rows\n",
      "Length of data set after dropping all rows with less than 10 games played: 27308 rows\n",
      "Columns with missing data:\n",
      "Age      12\n",
      "GS     7706\n",
      "MP      939\n",
      "3P     5725\n",
      "3PA    5725\n",
      "3P%    8346\n",
      "2P%       1\n",
      "FT%      85\n",
      "ORB    4153\n",
      "DRB    4153\n",
      "TRB     769\n",
      "STL    4969\n",
      "BLK    4968\n",
      "TOV    5068\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Columns with missing data after filling:\n",
      "3P%    0\n",
      "2P%    0\n",
      "FT%    0\n",
      "Age    0\n",
      "GS     0\n",
      "MP     0\n",
      "3P     0\n",
      "3PA    0\n",
      "ORB    0\n",
      "DRB    0\n",
      "TRB    0\n",
      "STL    0\n",
      "BLK    0\n",
      "TOV    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "nba_df = pd.read_csv('player_totals.csv', encoding = 'unicode_escape', engine ='python')\n",
    "\n",
    "print(f\"Original data set length: {len(nba_df)} rows\")\n",
    "\n",
    "season2024_condition = nba_df['Season'] > 2023\n",
    "nba_df.drop(index=nba_df[season2024_condition].index, inplace=True)\n",
    "\n",
    "# season2005_condition = nba_df['Season'] <= 2005\n",
    "# nba_df.drop(index=nba_df[season2005_condition].index, inplace=True)\n",
    "\n",
    "# targeting modern game\n",
    "\n",
    "print(f\"Length of data set after dropping the 2024 season: {len(nba_df)} rows\")\n",
    "\n",
    "gp_condition = nba_df[\"GP\"] <= 10\n",
    "nba_df.drop(index=nba_df[gp_condition].index, inplace=True)\n",
    "\n",
    "print(f\"Length of data set after dropping all rows with less than 10 games played: {len(nba_df)} rows\")\n",
    "\n",
    "# nba_df = nba_df.dropna()\n",
    "\n",
    "# print(f\"Length of data set after dropping all rows with NA values: {len(nba_df)} rows\")\n",
    "\n",
    "missing_data = nba_df.isnull().sum()\n",
    "\n",
    "print(\"Columns with missing data:\")\n",
    "print(missing_data[missing_data > 0])\n",
    "print(\"\\n\")\n",
    "\n",
    "columns_to_fill = ['3P%', '2P%', 'FT%', 'Age', 'GS', 'MP', '3P', '3PA', 'ORB', 'DRB', 'TRB', 'STL', 'BLK', 'TOV']\n",
    "\n",
    "nba_df[columns_to_fill] = nba_df[columns_to_fill].fillna(0)\n",
    "\n",
    "missing_data_updated = nba_df[columns_to_fill].isnull().sum()\n",
    "\n",
    "print('Columns with missing data after filling:')\n",
    "print(missing_data_updated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Linear Regression and Cross-Validation:\n",
      "MSE: 3318.2778205637574\n",
      "MAE: 37.399940900823395\n",
      "R-squared: 0.9858163503124384\n",
      "Adjusted R-squared: 0.9858142723503555\n",
      "Fold 1: Min PTS: 6, Max PTS: 2822\n",
      "Fold 2: Min PTS: 2, Max PTS: 3033\n",
      "Fold 3: Min PTS: 4, Max PTS: 2719\n",
      "Fold 4: Min PTS: 8, Max PTS: 2633\n",
      "Fold 5: Min PTS: 2, Max PTS: 2719\n",
      "Fold 6: Min PTS: 1, Max PTS: 4029\n",
      "Fold 7: Min PTS: 3, Max PTS: 3586\n",
      "Fold 8: Min PTS: 2, Max PTS: 2948\n",
      "Fold 9: Min PTS: 5, Max PTS: 3041\n",
      "Fold 10: Min PTS: 4, Max PTS: 2495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Extract features and target variable\n",
    "X = nba_df[[\"GP\", \"MP\", \"FG%\", \"FG\"]]\n",
    "y_pts = nba_df[\"PTS\"]\n",
    "\n",
    "# Create and fit the scaler on the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Create KFold cross-validator\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=13)\n",
    "\n",
    "# Initialize lists to store min and max values for each fold\n",
    "min_y_pts_values = []\n",
    "max_y_pts_values = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y_pts.iloc[train_index], y_pts.iloc[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate min and max values for this fold\n",
    "    min_y_pts_values.append(min(y_test))\n",
    "    max_y_pts_values.append(max(y_test))\n",
    "\n",
    "# Calculate mean values of metrics\n",
    "mse_pts_mean = -np.mean(cross_val_score(model, X_scaled, y_pts, cv=kf, scoring='neg_mean_squared_error'))\n",
    "mae_pts_mean = -np.mean(cross_val_score(model, X_scaled, y_pts, cv=kf, scoring='neg_mean_absolute_error'))\n",
    "r2_pts_mean = np.mean(cross_val_score(model, X_scaled, y_pts, cv=kf, scoring='r2'))\n",
    "\n",
    "# Calculate adjusted R-squared\n",
    "n = len(y_pts)\n",
    "k = X.shape[1]\n",
    "adjusted_r2_pts = 1 - ((1 - r2_pts_mean) * (n - 1) / (n - k - 1))\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Linear Regression and Cross-Validation:\")\n",
    "print(f\"MSE: {mse_pts_mean}\")\n",
    "print(f\"MAE: {mae_pts_mean}\")\n",
    "print(f\"R-squared: {r2_pts_mean}\")\n",
    "print(f\"Adjusted R-squared: {adjusted_r2_pts}\")\n",
    "\n",
    "# Print min and max values for each fold\n",
    "for i, (min_val, max_val) in enumerate(zip(min_y_pts_values, max_y_pts_values), 1):\n",
    "    print(f\"Fold {i}: Min PTS: {min_val}, Max PTS: {max_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Justification\n",
    "The choice to use linear regression was due to the fact that the relationship between the features and the target variable was linear. So any changes to one of them would affect the outcome of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Untuned Random Forest Model and 10-fold Cross-Validation:\n",
      "MSE: 3653.0698892261585\n",
      "MAE: 37.092705480288046\n",
      "R-squared: 0.98399982360813\n",
      "Adjusted R-squared: 0.983997479517533\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Create and fit the scaler on the entire data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create the Random Forest regression model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform 10-fold cross-validation with parallel processing\n",
    "cv_mse_pts = -cross_val_score(rf_model, X_scaled, y_pts, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "cv_mae_pts = -cross_val_score(rf_model, X_scaled, y_pts, cv=10, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "cv_r2_pts = cross_val_score(rf_model, X_scaled, y_pts, cv=10, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Calculate mean values of metrics\n",
    "mse_pts_mean = np.mean(cv_mse_pts)\n",
    "mae_pts_mean = np.mean(cv_mae_pts)\n",
    "r2_pts_mean = np.mean(cv_r2_pts)\n",
    "\n",
    "# Calculate adjusted R-squared\n",
    "n = len(y_pts)\n",
    "k = X_scaled.shape[1]\n",
    "adjusted_r2_pts = 1 - ((1 - r2_pts_mean) * (n - 1) / (n - k - 1))\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Untuned Random Forest Model and 10-fold Cross-Validation:\")\n",
    "print(f\"MSE: {mse_pts_mean}\")\n",
    "print(f\"MAE: {mae_pts_mean}\")\n",
    "print(f\"R-squared: {r2_pts_mean}\")\n",
    "print(f\"Adjusted R-squared: {adjusted_r2_pts}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Retraining with Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Grid Search Random Forest Regression Model (Cross-Validation):\n",
      "MSE: 2121.730875379217\n",
      "MAE: 29.681374821723534\n",
      "R-squared: 0.9909330036905352\n",
      "Adjusted R-squared: 0.9909316753388802\n",
      "Grid Search with Cross-Validation took 1734.83 seconds.\n",
      "Average CPU Usage: 84.38%\n",
      "Average Memory Usage: 61.339999999999996%\n",
      "Best Hyperparameters:\n",
      "{'bootstrap': True, 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['log2', 'sqrt', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "\n",
    "# Define a custom scorer for adjusted R-squared\n",
    "def adjusted_r2_scorer(estimator, X, y):\n",
    "    n = len(y)\n",
    "    k = X.shape[1]\n",
    "    r2 = r2_score(y, estimator.predict(X))\n",
    "    return 1 - (1 - r2) * (n - 1) / (n - k - 1)\n",
    "\n",
    "# Create the Random Forest regression model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    rf_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring={'neg_mean_squared_error': 'neg_mean_squared_error', 'adjusted_r2': make_scorer(adjusted_r2_scorer)},\n",
    "    refit='neg_mean_squared_error',  # Refit using neg_mean_squared_error for predictions\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Create and fit the scaler on the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Monitor CPU and memory usage during grid search\n",
    "cpu_percentages = []\n",
    "memory_percentages = []\n",
    "\n",
    "# Fit the model to the data and perform cross-validation\n",
    "for i, (train_index, test_index) in enumerate(grid_search.cv.split(X_scaled, y_pts)):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y_pts.iloc[train_index], y_pts.iloc[test_index]\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Monitor CPU and memory usage\n",
    "    cpu_percentages.append(psutil.cpu_percent())\n",
    "    memory_percentages.append(psutil.virtual_memory().percent)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Get the best hyperparameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a new Random Forest model with the best hyperparameters\n",
    "best_rf_model = RandomForestRegressor(random_state=13, **best_params).fit(X_scaled, y_pts)\n",
    "\n",
    "# Calculate adjusted R-squared for the best model\n",
    "best_rf_model_r2 = r2_score(y_pts, best_rf_model.predict(X_scaled))\n",
    "adjusted_r2 = 1 - (1 - best_rf_model_r2) * (len(y_pts) - 1) / (len(y_pts) - X_scaled.shape[1] - 1)\n",
    "\n",
    "# Predictions\n",
    "y_pts_pred_tuned_rf = best_rf_model.predict(X_scaled)\n",
    "\n",
    "# Evaluation for Points (PTS) with tuned Random Forest model\n",
    "mse_pts_tuned_rf = mean_squared_error(y_pts, y_pts_pred_tuned_rf)\n",
    "mae_pts_tuned_rf = mean_absolute_error(y_pts, y_pts_pred_tuned_rf)\n",
    "r2_pts_tuned_rf = best_rf_model_r2\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Grid Search Random Forest Regression Model (Cross-Validation):\")\n",
    "print(f\"MSE: {mse_pts_tuned_rf}\")\n",
    "print(f\"MAE: {mae_pts_tuned_rf}\")\n",
    "print(f\"R-squared: {r2_pts_tuned_rf}\")\n",
    "print(f\"Adjusted R-squared: {adjusted_r2}\")\n",
    "print(f\"Grid Search with Cross-Validation took {elapsed_time_rounded} seconds.\")\n",
    "\n",
    "# Print average CPU and memory usage during grid search\n",
    "print(f\"Average CPU Usage: {np.mean(cpu_percentages)}%\")\n",
    "print(f\"Average Memory Usage: {np.mean(memory_percentages)}%\")\n",
    "\n",
    "# Print the best Hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Retraining with Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Randomized Search Random Forest Regression Model:\n",
      "MSE: 2121.730875379217\n",
      "MAE: 29.681374821723534\n",
      "R-squared: 0.9909330036905352\n",
      "Adjusted R-squared: 0.9909316753388802\n",
      "Randomized Search took 71.32 seconds.\n",
      "Average CPU Usage: 39.8%\n",
      "Average Memory Usage: 59.2%\n",
      "Best Hyperparameters:\n",
      "{'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# Assuming X and y are your features and target variable\n",
    "X = nba_df[[\"GP\", \"MP\", \"FG%\", \"FG\"]]\n",
    "y_pts = nba_df[\"PTS\"]\n",
    "\n",
    "# Create and fit the scaler on the entire data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define the hyperparameter grid for Random Forest\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['log2', 'sqrt', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "\n",
    "# Create the Random Forest regression model\n",
    "rf_model = RandomForestRegressor(random_state=13)\n",
    "\n",
    "# Create the RandomizedSearchCV object with 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=13)\n",
    "randomized_search = RandomizedSearchCV(\n",
    "    rf_model, param_distributions=param_dist, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1\n",
    ")\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Monitor CPU and memory usage during randomized search\n",
    "cpu_percentages = []\n",
    "memory_percentages = []\n",
    "\n",
    "# Fit the model to the data\n",
    "randomized_search.fit(X_scaled, y_pts)\n",
    "\n",
    "# Monitor CPU and memory usage\n",
    "cpu_percentages.append(psutil.cpu_percent())\n",
    "memory_percentages.append(psutil.virtual_memory().percent)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = randomized_search.best_params_\n",
    "\n",
    "# Create a new Random Forest model with the best hyperparameters\n",
    "best_rf_model = RandomForestRegressor(random_state=13, **best_params).fit(X_scaled, y_pts)\n",
    "\n",
    "# Predictions\n",
    "y_pts_pred_tuned_rf = best_rf_model.predict(X_scaled)\n",
    "\n",
    "# Evaluation for Points (PTS) with tuned Random Forest model\n",
    "mse_pts_tuned_rf = mean_squared_error(y_pts, y_pts_pred_tuned_rf)\n",
    "mae_pts_tuned_rf = mean_absolute_error(y_pts, y_pts_pred_tuned_rf)\n",
    "r2_pts_tuned_rf = r2_score(y_pts, y_pts_pred_tuned_rf)\n",
    "adj_r2_pts_tuned_rf = 1 - (1 - r2_pts_tuned_rf) * (len(y_pts) - 1) / (len(y_pts) - X.shape[1] - 1)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Randomized Search Random Forest Regression Model:\")\n",
    "print(f\"MSE: {mse_pts_tuned_rf}\")\n",
    "print(f\"MAE: {mae_pts_tuned_rf}\")\n",
    "print(f\"R-squared: {r2_pts_tuned_rf}\")\n",
    "print(f\"Adjusted R-squared: {adj_r2_pts_tuned_rf}\")\n",
    "print(f\"Randomized Search took {elapsed_time_rounded} seconds.\")\n",
    "\n",
    "# Print average CPU and memory usage during randomized search\n",
    "print(f\"Average CPU Usage: {np.mean(cpu_percentages)}%\")\n",
    "print(f\"Average Memory Usage: {np.mean(memory_percentages)}%\")\n",
    "\n",
    "# Print the best Hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with k-Nearest Neighbors Regression and 10-fold Cross-Validation:\n",
      "MSE: 3888.570610106457\n",
      "MAE: 40.634687603864464\n",
      "R-squared: 0.9833804999395147\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X and y are your features and target variable\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert y_pts to a NumPy array\n",
    "y_pts_array = y_pts.values  # No need to reshape for 1D array\n",
    "\n",
    "# Create kNN regression model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_mse = -cross_val_score(knn_model, X_scaled, y_pts_array, cv=kf, scoring='neg_mean_squared_error')\n",
    "cv_mae = -cross_val_score(knn_model, X_scaled, y_pts_array, cv=kf, scoring='neg_mean_absolute_error')\n",
    "cv_r2 = cross_val_score(knn_model, X_scaled, y_pts_array, cv=kf, scoring='r2')\n",
    "\n",
    "# Calculate mean values of metrics\n",
    "mse_mean = np.mean(cv_mse)\n",
    "mae_mean = np.mean(cv_mae)\n",
    "r2_mean = np.mean(cv_r2)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with k-Nearest Neighbors Regression and 10-fold Cross-Validation:\")\n",
    "print(f\"MSE: {mse_mean}\")\n",
    "print(f\"MAE: {mae_mean}\")\n",
    "print(f\"R-squared: {r2_mean}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Retraining with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression and 10-fold Cross-Validation:\n",
      "MSE: 3607.4618754743597\n",
      "MAE: 39.178379436308916\n",
      "R-squared: 0.9845863350330074\n",
      "Grid Search took 43.31 seconds.\n",
      "Average CPU Usage: 9.2%\n",
      "Average Memory Usage: 64.5%\n",
      "Best Hyperparameters:\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 9, 'p': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X and y are your features and target variable\n",
    "X = nba_df[[\"GP\", \"MP\", \"FG%\", \"FG\"]]\n",
    "y_pts = nba_df[\"PTS\"]\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': [20, 30, 40],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create kNN regression model\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Record memory and CPU usage\n",
    "cpu_percentages = []\n",
    "memory_percentages = []\n",
    "\n",
    "def get_resource_usage():\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "    memory_percent = psutil.virtual_memory().percent\n",
    "    return cpu_percent, memory_percent\n",
    "\n",
    "# Create a custom scorer for explained_variance to use in cross_val_score\n",
    "explained_variance_scorer = make_scorer(lambda y, y_pred: r2_score(y, y_pred), greater_is_better=True)\n",
    "\n",
    "grid_search = GridSearchCV(knn_model, param_grid=param_grid, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_scaled, y_pts)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Record memory and CPU usage during grid search\n",
    "cpu_percentages.append(psutil.cpu_percent())\n",
    "memory_percentages.append(psutil.virtual_memory().percent)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a new KNN model with the best hyperparameters\n",
    "best_knn_model = KNeighborsRegressor(**best_params)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_mse = -cross_val_score(best_knn_model, X_scaled, y_pts, cv=kf, scoring='neg_mean_squared_error')\n",
    "cv_mae = -cross_val_score(best_knn_model, X_scaled, y_pts, cv=kf, scoring='neg_mean_absolute_error')\n",
    "cv_r2 = cross_val_score(best_knn_model, X_scaled, y_pts, cv=kf, scoring='r2')\n",
    "cv_adj_r2 = cross_val_score(best_knn_model, X_scaled, y_pts, cv=kf, scoring=explained_variance_scorer)\n",
    "\n",
    "# Calculate mean values of metrics\n",
    "mse_mean = np.mean(cv_mse)\n",
    "mae_mean = np.mean(cv_mae)\n",
    "r2_mean = np.mean(cv_r2)\n",
    "adj_r2_mean = np.mean(cv_adj_r2)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression and 10-fold Cross-Validation:\")\n",
    "print(f\"MSE: {mse_mean}\")\n",
    "print(f\"MAE: {mae_mean}\")\n",
    "print(f\"R-squared: {r2_mean}\")\n",
    "print(f\"Grid Search took {elapsed_time_rounded} seconds.\")\n",
    "\n",
    "# Print average CPU and memory usage during grid search\n",
    "print(f\"Average CPU Usage: {np.mean(cpu_percentages)}%\")\n",
    "print(f\"Average Memory Usage: {np.mean(memory_percentages)}%\")\n",
    "\n",
    "# Print the best Hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Retraining with Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression (Randomized Search)\n",
      "MSE: 3889.8392584749695\n",
      "MAE: 40.347583659548185\n",
      "R-squared (CV): 0.9840094521432474\n",
      "Adjusted R-squared (CV): 0.9840346933017091\n",
      "Randomized Search took 3.34 seconds.\n",
      "Average CPU Usage: 6.8%\n",
      "Average Memory Usage: 64.9%\n",
      "Best Hyperparameters:\n",
      "{'weights': 'distance', 'p': 2, 'n_neighbors': 9, 'leaf_size': 40, 'algorithm': 'kd_tree'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import time\n",
    "import numpy as np\n",
    "import psutil\n",
    "\n",
    "# Assuming X and y are your features and target variable\n",
    "X = nba_df[[\"GP\", \"MP\", \"FG%\", \"FG\"]]\n",
    "y_pts = nba_df[\"PTS\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_pts, test_size=0.4, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "param_dist = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': [20, 30, 40],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create kNN regression model\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "# Create KFold for cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Monitor CPU and memory usage during randomized search\n",
    "cpu_percentages = []\n",
    "memory_percentages = []\n",
    "\n",
    "# Create RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(\n",
    "    knn_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='neg_mean_squared_error', n_jobs=1, random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model to the data\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Monitor CPU and memory usage\n",
    "cpu_percentages.append(psutil.cpu_percent())\n",
    "memory_percentages.append(psutil.virtual_memory().percent)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Create a new KNN model with the best hyperparameters\n",
    "best_knn_model = KNeighborsRegressor(**best_params).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Perform cross-validation for adjusted R-squared\n",
    "cv_r2 = cross_val_score(best_knn_model, X_train_scaled, y_train, cv=kf, scoring='r2')\n",
    "cv_adj_r2 = cross_val_score(best_knn_model, X_train_scaled, y_train, cv=kf, scoring='explained_variance')\n",
    "\n",
    "# Calculate mean values of metrics\n",
    "r2_mean = np.mean(cv_r2)\n",
    "adj_r2_mean = np.mean(cv_adj_r2)\n",
    "\n",
    "# Predictions\n",
    "y_pts_pred_tuned_knn = best_knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pts_pred_tuned_knn)\n",
    "mae = mean_absolute_error(y_test, y_pts_pred_tuned_knn)\n",
    "r2 = r2_score(y_test, y_pts_pred_tuned_knn)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression (Randomized Search)\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared (CV): {r2_mean}\")\n",
    "print(f\"Adjusted R-squared (CV): {adj_r2_mean}\")\n",
    "print(f\"Randomized Search took {elapsed_time_rounded} seconds.\")\n",
    "\n",
    "# Print average CPU and memory usage during randomized search\n",
    "print(f\"Average CPU Usage: {np.mean(cpu_percentages)}%\")\n",
    "print(f\"Average Memory Usage: {np.mean(memory_percentages)}%\")\n",
    "\n",
    "# Print the best Hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
