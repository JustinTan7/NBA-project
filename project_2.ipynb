{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Preparing and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data set length: 31550 rows\n",
      "Length of data set after dropping all seasons before 2005 and 2032 season: 11236 rows\n",
      "Length of data set after dropping all rows with less than 10 games played: 9686 rows\n",
      "\n",
      "\n",
      "Columns with missing data:\n",
      "3P%    911\n",
      "2P%      1\n",
      "FT%     54\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Columns with missing data after filling:\n",
      "FG%     0\n",
      "3P%     0\n",
      "2P%     0\n",
      "eFG%    0\n",
      "FT%     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "nba_df = pd.read_csv('player_totals.csv', encoding = 'unicode_escape', engine ='python')\n",
    "\n",
    "print(f\"Original data set length: {len(nba_df)} rows\")\n",
    "\n",
    "season2024_condition = nba_df['Season'] > 2023\n",
    "nba_df.drop(index=nba_df[season2024_condition].index, inplace=True)\n",
    "\n",
    "season2005_condition = nba_df['Season'] <= 2005\n",
    "nba_df.drop(index=nba_df[season2005_condition].index, inplace=True)\n",
    "\n",
    "print(f\"Length of data set after dropping all seasons before 2005 and dropping the 2023 season: {len(nba_df)} rows\")\n",
    "\n",
    "gp_condition = nba_df[\"GP\"] <= 10\n",
    "nba_df.drop(index=nba_df[gp_condition].index, inplace=True)\n",
    "\n",
    "print(f\"Length of data set after dropping all rows with less than 10 games played: {len(nba_df)} rows\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "missing_data = nba_df.isnull().sum()\n",
    "\n",
    "print(\"Columns with missing data:\")\n",
    "print(missing_data[missing_data > 0])\n",
    "print(\"\\n\")\n",
    "\n",
    "columns_to_fill = ['FG%', '3P%', '2P%', 'eFG%', 'FT%' ]\n",
    "\n",
    "nba_df[columns_to_fill] = nba_df[columns_to_fill].fillna(0)\n",
    "\n",
    "missing_data_updated = nba_df[columns_to_fill].isnull().sum()\n",
    "\n",
    "print('Columns with missing data after filling:')\n",
    "print(missing_data_updated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Linear Regression:\n",
      "MSE: 26961.91884372399\n",
      "MAE: 109.11193790799443\n",
      "R-squared: 0.8627768411548458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Extract features and target variable\n",
    "X = nba_df[[\"GP\", \"MP\", \"FG%\", \"3P%\", \"2P%\", \"FT%\"]]\n",
    "y_pts = nba_df[\"PTS\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_pts_train, y_pts_test = train_test_split(\n",
    "    X, y_pts, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# Create and fit the scaler on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train linear regression model on scaled data\n",
    "model_pts_scaled = LinearRegression().fit(X_train_scaled, y_pts_train)\n",
    "\n",
    "# Predictions on scaled data\n",
    "y_pts_pred_scaled = model_pts_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation for Points (PTS) on scaled data\n",
    "mse_pts_scaled = mean_squared_error(y_pts_test, y_pts_pred_scaled)\n",
    "mae_pts_scaled = mean_absolute_error(y_pts_test, y_pts_pred_scaled)\n",
    "r2_pts_scaled = r2_score(y_pts_test, y_pts_pred_scaled)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Linear Regression:\")\n",
    "print(f\"MSE: {mse_pts_scaled}\")\n",
    "print(f\"MAE: {mae_pts_scaled}\")\n",
    "print(f\"R-squared: {r2_pts_scaled}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Justification\n",
    "The choice to use linear regression was due to the fact that the relationship between the features and the target variable was linear. So any changes to one of them would affect the outcome of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Untuned Random Forest Model:\n",
      "MSE: 21178.11296469677\n",
      "MAE: 91.50268903225808\n",
      "R-squared: 0.8922136226193829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_pts_train, y_pts_test = train_test_split(\n",
    "    X, y_pts, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# Create and fit the scaler on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Random Forest regression model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model to the scaled data\n",
    "rf_model.fit(X_train_scaled, y_pts_train)\n",
    "\n",
    "# Predictions on scaled data\n",
    "y_pts_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation for Points (PTS) with untuned Random Forest model and scaling\n",
    "mse_pts_rf = mean_squared_error(y_pts_test, y_pts_pred_rf)\n",
    "mae_pts_rf = mean_absolute_error(y_pts_test, y_pts_pred_rf)\n",
    "r2_pts_rf = r2_score(y_pts_test, y_pts_pred_rf)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Untuned Random Forest Model:\")\n",
    "print(f\"MSE: {mse_pts_rf}\")\n",
    "print(f\"MAE: {mae_pts_rf}\")\n",
    "print(f\"R-squared: {r2_pts_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Retraining with Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Grid Search Random Forest Regression Model:\n",
      "MSE: 20796.84414034716\n",
      "MAE: 90.50302128608358\n",
      "R-squared: 0.8941540969880538\n",
      "Grid Search took 804.74 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_pts_train, y_pts_test = train_test_split(\n",
    "    X, y_pts, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# Create and fit the scaler on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the hyperparameter grid for Random Forest\n",
    "# CHANGE THE PARAMETERS TO 6\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "\n",
    "# Create the Random Forest regression model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train_scaled, y_pts_train)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a new Random Forest model with the best hyperparameters\n",
    "best_rf_model = RandomForestRegressor(random_state=42, **best_params).fit(X_train_scaled, y_pts_train)\n",
    "\n",
    "# Predictions\n",
    "y_pts_pred_tuned_rf = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation for Points (PTS) with tuned Random Forest model\n",
    "mse_pts_tuned_rf = mean_squared_error(y_pts_test, y_pts_pred_tuned_rf)\n",
    "mae_pts_tuned_rf = mean_absolute_error(y_pts_test, y_pts_pred_tuned_rf)\n",
    "r2_pts_tuned_rf = r2_score(y_pts_test, y_pts_pred_tuned_rf)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Grid Search Random Forest Regression Model:\")\n",
    "print(f\"MSE: {mse_pts_tuned_rf}\")\n",
    "print(f\"MAE: {mae_pts_tuned_rf}\")\n",
    "print(f\"R-squared: {r2_pts_tuned_rf}\")\n",
    "print(f\"Grid Search took {elapsed_time_rounded} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Retraining with Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "10 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\justi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [            nan -21075.06551797 -21625.44597388             nan\n",
      " -20980.39233275 -21127.88973103 -21511.78798928 -21495.66649815\n",
      " -21746.32003295 -21191.08733663]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Randomized Search Random Forest Regression Model:\n",
      "MSE: 20503.657813162612\n",
      "MAE: 91.30154959139786\n",
      "R-squared: 0.8956462739425082\n",
      "Randomized Search took 83.58 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_pts_train, y_pts_test = train_test_split(\n",
    "    X, y_pts, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# Create and fit the scaler on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the hyperparameter grid for Random Forest\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Create the Random Forest regression model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "randomized_search = RandomizedSearchCV(rf_model, param_distributions=param_dist, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model to the data\n",
    "randomized_search.fit(X_train_scaled, y_pts_train)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = randomized_search.best_params_\n",
    "\n",
    "# Create a new Random Forest model with the best hyperparameters\n",
    "best_rf_model = RandomForestRegressor(random_state=42, **best_params).fit(X_train_scaled, y_pts_train)\n",
    "\n",
    "# Predictions\n",
    "y_pts_pred_tuned_rf = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation for Points (PTS) with tuned Random Forest model\n",
    "mse_pts_tuned_rf = mean_squared_error(y_pts_test, y_pts_pred_tuned_rf)\n",
    "mae_pts_tuned_rf = mean_absolute_error(y_pts_test, y_pts_pred_tuned_rf)\n",
    "r2_pts_tuned_rf = r2_score(y_pts_test, y_pts_pred_tuned_rf)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Randomized Search Random Forest Regression Model:\")\n",
    "print(f\"MSE: {mse_pts_tuned_rf}\")\n",
    "print(f\"MAE: {mae_pts_tuned_rf}\")\n",
    "print(f\"R-squared: {r2_pts_tuned_rf}\")\n",
    "\n",
    "print(f\"Randomized Search took {elapsed_time_rounded} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Untuned k-Nearest Neigbours Regression\n",
      "MSE: 25386.66116129032\n",
      "MAE: 103.72490322580646\n",
      "R-squared: 0.8707941427583242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X and y are your features and target variable\n",
    "X = nba_df[[\"GP\", \"MP\", \"FG%\", \"3P%\", \"2P%\", \"FT%\"]]\n",
    "y_pts = nba_df[\"PTS\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_pts, test_size=0.4, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create kNN regression model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors\n",
    "\n",
    "# Fit the model to the data\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Untuned k-Nearest Neigbours Regression\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Retraining with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression\n",
      "MSE: 22665.662973350594\n",
      "MAE: 99.85248456114738\n",
      "R-squared: 0.8846427107599278\n",
      "Grid Search took 2.14 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# Assuming X and y are your features and target variable\n",
    "X = nba_df[[\"GP\", \"MP\", \"FG%\", \"3P%\", \"2P%\", \"FT%\"]]\n",
    "y_pts = nba_df[\"PTS\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_pts, test_size=0.4, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "param_dist = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': [20, 30, 40],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create kNN regression model\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(knn_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a new KNN model with the best hyperparameters\n",
    "best_knn_model = KNeighborsRegressor(**best_params).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pts_pred_tuned_knn = best_knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pts_pred_tuned_knn)\n",
    "mae = mean_absolute_error(y_test, y_pts_pred_tuned_knn)\n",
    "r2 = r2_score(y_test, y_pts_pred_tuned_knn)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Grid Search took {elapsed_time_rounded} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Retraining with Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression (Randomized Search)\n",
      "MSE: 22665.662973350594\n",
      "MAE: 99.85248456114738\n",
      "R-squared: 0.8846427107599278\n",
      "Randomized Search took 1.82 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Assuming X and y are your features and target variable\n",
    "X = nba_df[[\"GP\", \"MP\", \"FG%\", \"3P%\", \"2P%\", \"FT%\"]]\n",
    "y_pts = nba_df[\"PTS\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_pts, test_size=0.4, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "param_dist = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': [20, 30, 40],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create kNN regression model\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "random_search = RandomizedSearchCV(knn_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model to the data\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Round the elapsed time to two decimal places\n",
    "elapsed_time_rounded = round(elapsed_time, 2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Create a new KNN model with the best hyperparameters\n",
    "best_knn_model = KNeighborsRegressor(**best_params).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pts_pred_tuned_knn = best_knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pts_pred_tuned_knn)\n",
    "mae = mean_absolute_error(y_test, y_pts_pred_tuned_knn)\n",
    "r2 = r2_score(y_test, y_pts_pred_tuned_knn)\n",
    "\n",
    "print(\"Metrics for Points (PTS) with Tuned k-Nearest Neighbors Regression (Randomized Search)\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Randomized Search took {elapsed_time_rounded} seconds.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
